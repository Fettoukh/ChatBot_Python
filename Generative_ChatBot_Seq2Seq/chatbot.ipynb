{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fettoukh Mohamed Amine - Omri Ahmed\n",
    "## chatbot génératif en utilisant le modèle seq2seq\n",
    "\n",
    "#### Un chatbot est un logiciel qui offre une véritable expérience conversationnelle à l'utilisateur. Il existe des chatbots à domaine fermé et des chatbots à domaine ouvert (génératif). Le chatbot à domaine fermé est un chatbot qui répond avec des textes prédéfinis. Un chatbot génératif génère une réponse comme son nom l'indique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importer les librairies nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\omri6\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.1)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\omri6\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "!pip install tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prétraitement de l'ensemble de données\n",
    "- L'ensemble de données que nous allons utiliser est collecté auprès de Kaggle. Il contient des réponses humaines et des réponses de bot. Il y a 2363 entrées pour chacun.\n",
    "\n",
    "- Tout d'abord, nous devrons nettoyer notre corpus à l'aide d'expressions régulières. Ensuite, nous devrons créer des paires comme la réponse humaine-bot afin de pouvoir entraîner notre modèle seq2seq. Nous effectuerons ces tâches comme indiqué ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2RjUhNsqY4L"
   },
   "outputs": [],
   "source": [
    "data_path = \"human_text.txt\"\n",
    "data_path2 = \"robot_text.txt\"\n",
    "# Defining lines as a list of each line\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "  lines = f.read().split('\\n')\n",
    "with open(data_path2, 'r', encoding='utf-8') as f:\n",
    "  lines2 = f.read().split('\\n')\n",
    "lines = [re.sub(r\"\\[\\w+\\]\",'hi',line) for line in lines]\n",
    "lines = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines]\n",
    "lines2 = [re.sub(r\"\\[\\w+\\]\",'',line) for line in lines2]\n",
    "lines2 = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines2]\n",
    "# Grouping lines by response pair\n",
    "pairs = list(zip(lines,lines2))\n",
    "#random.shuffle(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Après avoir créé des paires, nous pouvons également les mélanger avant l'entraînement.\n",
    "- Nous devrons créer des listes distinctes pour les séquences d'entrée et les séquences cibles et nous devrons également créer des listes pour les jetons uniques (jetons d'entrée et jetons cibles) dans notre ensemble de données. Pour les séquences cibles, nous ajouterons <START> au début de la séquence et '<END>' à la fin de la séquence afin que notre modèle sache par où commencer et terminer la génération de texte.\n",
    "#### Nous allons procéder comme indiqué ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "bw7iFyTEFriu",
    "outputId": "d10fd3a9-023e-4850-ef35-2dbac08098a0"
   },
   "outputs": [],
   "source": [
    "input_docs = []\n",
    "target_docs = []\n",
    "input_tokens = set()\n",
    "target_tokens = set()\n",
    "for line in pairs[:400]:\n",
    "  input_doc, target_doc = line[0], line[1]\n",
    "  # Appending each input sentence to input_docs\n",
    "  input_docs.append(input_doc)\n",
    "  # Splitting words from punctuation  \n",
    "  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
    "  # Redefine target_doc below and append it to target_docs\n",
    "  target_doc = '<START> ' + target_doc + ' <END>'\n",
    "  target_docs.append(target_doc)\n",
    "  \n",
    "  # Now we split up each sentence into words and add each unique word to our vocabulary set\n",
    "  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
    "    if token not in input_tokens:\n",
    "      input_tokens.add(token)\n",
    "  for token in target_doc.split():\n",
    "    if token not in target_tokens:\n",
    "      target_tokens.add(token)\n",
    "input_tokens = sorted(list(input_tokens))\n",
    "target_tokens = sorted(list(target_tokens))\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant créer un dictionnaire de caractéristiques d'entrée qui stockera nos jetons d'entrée sous forme de paires clé-valeur, le mot étant la clé et la valeur l'index. De même, pour les jetons cibles, nous allons créer un dictionnaire de fonctionnalités cibles. Le dictionnaire de fonctionnalités nous aidera à encoder nos phrases en vecteurs uniques. Après tout, les ordinateurs ne comprennent que les chiffres. Pour décoder les phrases, nous devrons créer le dictionnaire de caractéristiques inversé qui stocke l'index en tant que clé et le mot en tant que valeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(input_tokens)])\n",
    "target_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(target_tokens)])\n",
    "\n",
    "reverse_input_features_dict = dict(\n",
    "    (i, token) for token, i in input_features_dict.items())\n",
    "reverse_target_features_dict = dict(\n",
    "    (i, token) for token, i in target_features_dict.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration avant l'entrainement\n",
    "Pour entraîner notre modèle seq2seq, nous utiliserons trois matrices de vecteurs uniques, les données d'entrée du codeur, les données d'entrée du décodeur et les données de sortie du décodeur. La raison pour laquelle nous utilisons deux matrices pour le décodeur est une méthode appelée le forçage de l'enseignant qui est utilisée par le modèle seq2seq lors de la formation ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
    "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
    "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
    "        #Assign 1. for the current line, timestep, & word in encoder_input_data\n",
    "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
    "    \n",
    "    for timestep, token in enumerate(target_doc.split()):\n",
    "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
    "        if timestep > 0:\n",
    "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "NPRH_kUNKaHE",
    "outputId": "4fb20057-4685-4332-9dff-45b9de2fc7d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hi', 'hi there how are you'), ('oh thanks i m fine this is an evening in my timezone', 'here is afternoon'), ('how do you feel today tell me something about yourself', 'my name is rdany but you can call me dany the r means robot i hope we can be virtual friends'), ('how many virtual friends have you got', 'i have many but not enough to fully understand humans beings'), ('is that forbidden for you to tell the exact number', 'i ve talked with 143 users counting 7294 lines of text')]\n",
      "['hi', 'oh thanks i m fine this is an evening in my timezone', 'how do you feel today tell me something about yourself', 'how many virtual friends have you got', 'is that forbidden for you to tell the exact number']\n"
     ]
    }
   ],
   "source": [
    "print(pairs[:5])\n",
    "print(input_docs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration encodeur-décodeur\n",
    "Notre modèle de codeur nécessite une couche d'entrée qui définit une matrice pour contenir les vecteurs uniques et une couche LSTM avec un certain nombre d'états cachés. La structure du modèle de décodeur est presque la même que celle de l'encodeur, mais ici nous transmettons les données d'état avec les entrées du décodeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QZZcikCkFulO",
    "outputId": "d720c441-8b2b-4d6d-87c9-db0e3afe54eb"
   },
   "outputs": [],
   "source": [
    "#Dimensionality\n",
    "dimensionality = 256\n",
    "#The batch size and number of epochs\n",
    "batch_size = 10\n",
    "epochs = 600\n",
    "#Encoder\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
    "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_hidden, state_cell]\n",
    "#Decoder\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
    "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construire et former le modèle seq2seq\n",
    "Nous allons maintenant créer notre modèle seq2seq et l'entraîner avec les données de l'encodeur et du décodeur, comme indiqué ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "32/32 [==============================] - 24s 477ms/step - loss: 1.2464 - accuracy: 0.0224 - val_loss: 1.3501 - val_accuracy: 0.0200\n",
      "Epoch 2/600\n",
      "32/32 [==============================] - 14s 439ms/step - loss: 1.1804 - accuracy: 0.0240 - val_loss: 1.3719 - val_accuracy: 0.0200\n",
      "Epoch 3/600\n",
      "32/32 [==============================] - 14s 438ms/step - loss: 1.1756 - accuracy: 0.0244 - val_loss: 1.3889 - val_accuracy: 0.0198\n",
      "Epoch 4/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 1.1745 - accuracy: 0.0237 - val_loss: 1.4102 - val_accuracy: 0.0200\n",
      "Epoch 5/600\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 1.1853 - accuracy: 0.0229 - val_loss: 1.4862 - val_accuracy: 0.0160\n",
      "Epoch 6/600\n",
      "32/32 [==============================] - 13s 403ms/step - loss: 1.2411 - accuracy: 0.0201 - val_loss: 1.4704 - val_accuracy: 0.0192\n",
      "Epoch 7/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.1731 - accuracy: 0.0241 - val_loss: 1.4601 - val_accuracy: 0.0200\n",
      "Epoch 8/600\n",
      "32/32 [==============================] - 13s 403ms/step - loss: 1.1712 - accuracy: 0.0239 - val_loss: 1.4769 - val_accuracy: 0.0198\n",
      "Epoch 9/600\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 1.1691 - accuracy: 0.0239 - val_loss: 1.4965 - val_accuracy: 0.0200\n",
      "Epoch 10/600\n",
      "32/32 [==============================] - 13s 402ms/step - loss: 1.1690 - accuracy: 0.0235 - val_loss: 1.5114 - val_accuracy: 0.0200\n",
      "Epoch 11/600\n",
      "32/32 [==============================] - 13s 402ms/step - loss: 1.1700 - accuracy: 0.0238 - val_loss: 1.5292 - val_accuracy: 0.0200\n",
      "Epoch 12/600\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 1.1687 - accuracy: 0.0239 - val_loss: 1.5465 - val_accuracy: 0.0200\n",
      "Epoch 13/600\n",
      "32/32 [==============================] - 13s 398ms/step - loss: 1.1677 - accuracy: 0.0241 - val_loss: 1.5606 - val_accuracy: 0.0198\n",
      "Epoch 14/600\n",
      "32/32 [==============================] - 13s 404ms/step - loss: 1.1643 - accuracy: 0.0239 - val_loss: 1.5776 - val_accuracy: 0.0200\n",
      "Epoch 15/600\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 1.1644 - accuracy: 0.0241 - val_loss: 1.5923 - val_accuracy: 0.0200\n",
      "Epoch 16/600\n",
      "32/32 [==============================] - 13s 418ms/step - loss: 1.1644 - accuracy: 0.0239 - val_loss: 1.6032 - val_accuracy: 0.0200\n",
      "Epoch 17/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.1644 - accuracy: 0.0240 - val_loss: 1.6139 - val_accuracy: 0.0200\n",
      "Epoch 18/600\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 1.1623 - accuracy: 0.0239 - val_loss: 1.6251 - val_accuracy: 0.0200\n",
      "Epoch 19/600\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 1.1629 - accuracy: 0.0241 - val_loss: 1.6329 - val_accuracy: 0.0200\n",
      "Epoch 20/600\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.1716 - accuracy: 0.0233 - val_loss: 1.6000 - val_accuracy: 0.0200\n",
      "Epoch 21/600\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 1.1607 - accuracy: 0.0240 - val_loss: 1.6138 - val_accuracy: 0.0200\n",
      "Epoch 22/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.1620 - accuracy: 0.0239 - val_loss: 1.6242 - val_accuracy: 0.0200\n",
      "Epoch 23/600\n",
      "32/32 [==============================] - 13s 416ms/step - loss: 1.1957 - accuracy: 0.0226 - val_loss: 1.6315 - val_accuracy: 0.0200\n",
      "Epoch 24/600\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 1.1692 - accuracy: 0.0239 - val_loss: 1.6297 - val_accuracy: 0.0200\n",
      "Epoch 25/600\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.1631 - accuracy: 0.0241 - val_loss: 1.6346 - val_accuracy: 0.0200\n",
      "Epoch 26/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.1636 - accuracy: 0.0243 - val_loss: 1.6410 - val_accuracy: 0.0200\n",
      "Epoch 27/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.1602 - accuracy: 0.0237 - val_loss: 1.6422 - val_accuracy: 0.0200\n",
      "Epoch 28/600\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.1559 - accuracy: 0.0246 - val_loss: 1.6534 - val_accuracy: 0.0203\n",
      "Epoch 29/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.1595 - accuracy: 0.0245 - val_loss: 1.6527 - val_accuracy: 0.0200\n",
      "Epoch 30/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.1576 - accuracy: 0.0243 - val_loss: 1.6565 - val_accuracy: 0.0200\n",
      "Epoch 31/600\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 1.1561 - accuracy: 0.0240 - val_loss: 1.6600 - val_accuracy: 0.0198\n",
      "Epoch 32/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.1556 - accuracy: 0.0249 - val_loss: 1.6604 - val_accuracy: 0.0200\n",
      "Epoch 33/600\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 1.1533 - accuracy: 0.0251 - val_loss: 1.6616 - val_accuracy: 0.0203\n",
      "Epoch 34/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.1505 - accuracy: 0.0256 - val_loss: 1.6636 - val_accuracy: 0.0205\n",
      "Epoch 35/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.1505 - accuracy: 0.0256 - val_loss: 1.6661 - val_accuracy: 0.0198\n",
      "Epoch 36/600\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 1.1466 - accuracy: 0.0253 - val_loss: 1.6553 - val_accuracy: 0.0205\n",
      "Epoch 37/600\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.1469 - accuracy: 0.0258 - val_loss: 1.6630 - val_accuracy: 0.0200\n",
      "Epoch 38/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.1460 - accuracy: 0.0256 - val_loss: 1.6681 - val_accuracy: 0.0203\n",
      "Epoch 39/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 1.1471 - accuracy: 0.0252 - val_loss: 1.6637 - val_accuracy: 0.0213\n",
      "Epoch 40/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.1448 - accuracy: 0.0254 - val_loss: 1.6670 - val_accuracy: 0.0198\n",
      "Epoch 41/600\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 1.1453 - accuracy: 0.0258 - val_loss: 1.6611 - val_accuracy: 0.0210\n",
      "Epoch 42/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.1423 - accuracy: 0.0261 - val_loss: 1.6685 - val_accuracy: 0.0200\n",
      "Epoch 43/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.1408 - accuracy: 0.0262 - val_loss: 1.6712 - val_accuracy: 0.0200\n",
      "Epoch 44/600\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 1.1425 - accuracy: 0.0257 - val_loss: 1.6662 - val_accuracy: 0.0205\n",
      "Epoch 45/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.1413 - accuracy: 0.0259 - val_loss: 1.6701 - val_accuracy: 0.0205\n",
      "Epoch 46/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.1392 - accuracy: 0.0262 - val_loss: 1.6689 - val_accuracy: 0.0207\n",
      "Epoch 47/600\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 1.1373 - accuracy: 0.0262 - val_loss: 1.6725 - val_accuracy: 0.0210\n",
      "Epoch 48/600\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 1.1371 - accuracy: 0.0260 - val_loss: 1.6734 - val_accuracy: 0.0205\n",
      "Epoch 49/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.1435 - accuracy: 0.0261 - val_loss: 1.6671 - val_accuracy: 0.0205\n",
      "Epoch 50/600\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 1.1368 - accuracy: 0.0259 - val_loss: 1.6687 - val_accuracy: 0.0203\n",
      "Epoch 51/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.1356 - accuracy: 0.0262 - val_loss: 1.6693 - val_accuracy: 0.0207\n",
      "Epoch 52/600\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 1.1339 - accuracy: 0.0262 - val_loss: 1.6779 - val_accuracy: 0.0198\n",
      "Epoch 53/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.1336 - accuracy: 0.0269 - val_loss: 1.6820 - val_accuracy: 0.0195\n",
      "Epoch 54/600\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 1.1339 - accuracy: 0.0267 - val_loss: 1.6773 - val_accuracy: 0.0198\n",
      "Epoch 55/600\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 1.1338 - accuracy: 0.0264 - val_loss: 1.6747 - val_accuracy: 0.0200\n",
      "Epoch 56/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.1319 - accuracy: 0.0260 - val_loss: 1.6775 - val_accuracy: 0.0192\n",
      "Epoch 57/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 13s 410ms/step - loss: 1.1311 - accuracy: 0.0269 - val_loss: 1.6786 - val_accuracy: 0.0203\n",
      "Epoch 58/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.1358 - accuracy: 0.0265 - val_loss: 1.6759 - val_accuracy: 0.0207\n",
      "Epoch 59/600\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.1353 - accuracy: 0.0259 - val_loss: 1.6736 - val_accuracy: 0.0203\n",
      "Epoch 60/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.1280 - accuracy: 0.0266 - val_loss: 1.6799 - val_accuracy: 0.0210\n",
      "Epoch 61/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.1291 - accuracy: 0.0269 - val_loss: 1.6701 - val_accuracy: 0.0198\n",
      "Epoch 62/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 1.1261 - accuracy: 0.0271 - val_loss: 1.6753 - val_accuracy: 0.0198\n",
      "Epoch 63/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 1.1257 - accuracy: 0.0272 - val_loss: 1.6806 - val_accuracy: 0.0200\n",
      "Epoch 64/600\n",
      "32/32 [==============================] - 14s 428ms/step - loss: 1.1224 - accuracy: 0.0276 - val_loss: 1.6811 - val_accuracy: 0.0205\n",
      "Epoch 65/600\n",
      "32/32 [==============================] - 14s 429ms/step - loss: 1.1212 - accuracy: 0.0278 - val_loss: 1.6805 - val_accuracy: 0.0205\n",
      "Epoch 66/600\n",
      "32/32 [==============================] - 14s 425ms/step - loss: 1.1217 - accuracy: 0.0278 - val_loss: 1.6811 - val_accuracy: 0.0205\n",
      "Epoch 67/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 1.1229 - accuracy: 0.0272 - val_loss: 1.6770 - val_accuracy: 0.0200\n",
      "Epoch 68/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 1.1210 - accuracy: 0.0272 - val_loss: 1.6938 - val_accuracy: 0.0198\n",
      "Epoch 69/600\n",
      "32/32 [==============================] - 14s 427ms/step - loss: 1.1236 - accuracy: 0.0275 - val_loss: 1.6808 - val_accuracy: 0.0200\n",
      "Epoch 70/600\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 1.1205 - accuracy: 0.0278 - val_loss: 1.6851 - val_accuracy: 0.0195\n",
      "Epoch 71/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 1.1208 - accuracy: 0.0277 - val_loss: 1.6893 - val_accuracy: 0.0198\n",
      "Epoch 72/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 1.1192 - accuracy: 0.0278 - val_loss: 1.6832 - val_accuracy: 0.0200\n",
      "Epoch 73/600\n",
      "32/32 [==============================] - 14s 428ms/step - loss: 1.1205 - accuracy: 0.0277 - val_loss: 1.6834 - val_accuracy: 0.0190\n",
      "Epoch 74/600\n",
      "32/32 [==============================] - 14s 427ms/step - loss: 1.1165 - accuracy: 0.0279 - val_loss: 1.6871 - val_accuracy: 0.0192\n",
      "Epoch 75/600\n",
      "32/32 [==============================] - 14s 425ms/step - loss: 1.1162 - accuracy: 0.0280 - val_loss: 1.6836 - val_accuracy: 0.0195\n",
      "Epoch 76/600\n",
      "32/32 [==============================] - 14s 422ms/step - loss: 1.1154 - accuracy: 0.0278 - val_loss: 1.6866 - val_accuracy: 0.0198\n",
      "Epoch 77/600\n",
      "32/32 [==============================] - 14s 429ms/step - loss: 1.1128 - accuracy: 0.0277 - val_loss: 1.6864 - val_accuracy: 0.0190\n",
      "Epoch 78/600\n",
      "32/32 [==============================] - 14s 428ms/step - loss: 1.1135 - accuracy: 0.0282 - val_loss: 1.6886 - val_accuracy: 0.0195\n",
      "Epoch 79/600\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 1.1121 - accuracy: 0.0279 - val_loss: 1.6770 - val_accuracy: 0.0190\n",
      "Epoch 80/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 1.1163 - accuracy: 0.0279 - val_loss: 1.6820 - val_accuracy: 0.0205\n",
      "Epoch 81/600\n",
      "32/32 [==============================] - 14s 430ms/step - loss: 1.1138 - accuracy: 0.0279 - val_loss: 1.6825 - val_accuracy: 0.0200\n",
      "Epoch 82/600\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 1.1142 - accuracy: 0.0277 - val_loss: 1.6779 - val_accuracy: 0.0205\n",
      "Epoch 83/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 1.1127 - accuracy: 0.0278 - val_loss: 1.6862 - val_accuracy: 0.0207\n",
      "Epoch 84/600\n",
      "32/32 [==============================] - 14s 425ms/step - loss: 1.1115 - accuracy: 0.0282 - val_loss: 1.6966 - val_accuracy: 0.0195\n",
      "Epoch 85/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.1108 - accuracy: 0.0289 - val_loss: 1.6818 - val_accuracy: 0.0203\n",
      "Epoch 86/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.1130 - accuracy: 0.0284 - val_loss: 1.6844 - val_accuracy: 0.0203\n",
      "Epoch 87/600\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.1269 - accuracy: 0.0273 - val_loss: 1.6849 - val_accuracy: 0.0203\n",
      "Epoch 88/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.1092 - accuracy: 0.0286 - val_loss: 1.6906 - val_accuracy: 0.0205\n",
      "Epoch 89/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.1055 - accuracy: 0.0290 - val_loss: 1.6957 - val_accuracy: 0.0192\n",
      "Epoch 90/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.1038 - accuracy: 0.0296 - val_loss: 1.6908 - val_accuracy: 0.0203\n",
      "Epoch 91/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.1019 - accuracy: 0.0289 - val_loss: 1.6818 - val_accuracy: 0.0198\n",
      "Epoch 92/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.0981 - accuracy: 0.0299 - val_loss: 1.6859 - val_accuracy: 0.0205\n",
      "Epoch 93/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.0968 - accuracy: 0.0298 - val_loss: 1.6861 - val_accuracy: 0.0203\n",
      "Epoch 94/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.0954 - accuracy: 0.0299 - val_loss: 1.6864 - val_accuracy: 0.0198\n",
      "Epoch 95/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.1000 - accuracy: 0.0291 - val_loss: 1.6965 - val_accuracy: 0.0203\n",
      "Epoch 96/600\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.0987 - accuracy: 0.0299 - val_loss: 1.6988 - val_accuracy: 0.0203\n",
      "Epoch 97/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.1335 - accuracy: 0.0263 - val_loss: 1.6882 - val_accuracy: 0.0198\n",
      "Epoch 98/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.1104 - accuracy: 0.0286 - val_loss: 1.6875 - val_accuracy: 0.0205\n",
      "Epoch 99/600\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.1033 - accuracy: 0.0293 - val_loss: 1.6873 - val_accuracy: 0.0203\n",
      "Epoch 100/600\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 1.1007 - accuracy: 0.0296 - val_loss: 1.7006 - val_accuracy: 0.0200\n",
      "Epoch 101/600\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 1.0995 - accuracy: 0.0299 - val_loss: 1.6998 - val_accuracy: 0.0195\n",
      "Epoch 102/600\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 1.1012 - accuracy: 0.0296 - val_loss: 1.6993 - val_accuracy: 0.0200\n",
      "Epoch 103/600\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 1.0960 - accuracy: 0.0299 - val_loss: 1.6984 - val_accuracy: 0.0195\n",
      "Epoch 104/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.0944 - accuracy: 0.0297 - val_loss: 1.6998 - val_accuracy: 0.0205\n",
      "Epoch 105/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.0950 - accuracy: 0.0304 - val_loss: 1.7041 - val_accuracy: 0.0207\n",
      "Epoch 106/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.0948 - accuracy: 0.0305 - val_loss: 1.7012 - val_accuracy: 0.0205\n",
      "Epoch 107/600\n",
      "32/32 [==============================] - 13s 416ms/step - loss: 1.0922 - accuracy: 0.0302 - val_loss: 1.7029 - val_accuracy: 0.0198\n",
      "Epoch 108/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.0913 - accuracy: 0.0309 - val_loss: 1.6960 - val_accuracy: 0.0205\n",
      "Epoch 109/600\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 1.1040 - accuracy: 0.0299 - val_loss: 1.6826 - val_accuracy: 0.0200\n",
      "Epoch 110/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.1007 - accuracy: 0.0291 - val_loss: 1.6919 - val_accuracy: 0.0198\n",
      "Epoch 111/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.0922 - accuracy: 0.0296 - val_loss: 1.6791 - val_accuracy: 0.0192\n",
      "Epoch 112/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.1107 - accuracy: 0.0282 - val_loss: 1.6850 - val_accuracy: 0.0213\n",
      "Epoch 113/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 13s 411ms/step - loss: 1.1895 - accuracy: 0.0234 - val_loss: 1.6242 - val_accuracy: 0.0188\n",
      "Epoch 114/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.2068 - accuracy: 0.0226 - val_loss: 1.6190 - val_accuracy: 0.0185\n",
      "Epoch 115/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.1965 - accuracy: 0.0229 - val_loss: 1.6234 - val_accuracy: 0.0203\n",
      "Epoch 116/600\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.1798 - accuracy: 0.0243 - val_loss: 1.6126 - val_accuracy: 0.0203\n",
      "Epoch 117/600\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 1.1566 - accuracy: 0.0258 - val_loss: 1.6373 - val_accuracy: 0.0192\n",
      "Epoch 118/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.1390 - accuracy: 0.0264 - val_loss: 1.6452 - val_accuracy: 0.0205\n",
      "Epoch 119/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.1294 - accuracy: 0.0274 - val_loss: 1.6618 - val_accuracy: 0.0203\n",
      "Epoch 120/600\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.1195 - accuracy: 0.0280 - val_loss: 1.6760 - val_accuracy: 0.0200\n",
      "Epoch 121/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.1101 - accuracy: 0.0286 - val_loss: 1.6904 - val_accuracy: 0.0207\n",
      "Epoch 122/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.1036 - accuracy: 0.0295 - val_loss: 1.7019 - val_accuracy: 0.0200\n",
      "Epoch 123/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.1011 - accuracy: 0.0299 - val_loss: 1.6867 - val_accuracy: 0.0205\n",
      "Epoch 124/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.1022 - accuracy: 0.0301 - val_loss: 1.7090 - val_accuracy: 0.0203\n",
      "Epoch 125/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.0959 - accuracy: 0.0306 - val_loss: 1.7098 - val_accuracy: 0.0200\n",
      "Epoch 126/600\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 1.0998 - accuracy: 0.0304 - val_loss: 1.7037 - val_accuracy: 0.0215\n",
      "Epoch 127/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.1097 - accuracy: 0.0293 - val_loss: 1.7081 - val_accuracy: 0.0205\n",
      "Epoch 128/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.1030 - accuracy: 0.0292 - val_loss: 1.7028 - val_accuracy: 0.0207\n",
      "Epoch 129/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.0950 - accuracy: 0.0303 - val_loss: 1.7119 - val_accuracy: 0.0207\n",
      "Epoch 130/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.0931 - accuracy: 0.0303 - val_loss: 1.7234 - val_accuracy: 0.0200\n",
      "Epoch 131/600\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.0918 - accuracy: 0.0305 - val_loss: 1.7113 - val_accuracy: 0.0213\n",
      "Epoch 132/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 1.0911 - accuracy: 0.0308 - val_loss: 1.7154 - val_accuracy: 0.0200\n",
      "Epoch 133/600\n",
      "32/32 [==============================] - 13s 418ms/step - loss: 1.0937 - accuracy: 0.0318 - val_loss: 1.7100 - val_accuracy: 0.0210\n",
      "Epoch 134/600\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.0805 - accuracy: 0.0319 - val_loss: 1.7148 - val_accuracy: 0.0195\n",
      "Epoch 135/600\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 1.0821 - accuracy: 0.0316 - val_loss: 1.7152 - val_accuracy: 0.0198\n",
      "Epoch 136/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.0837 - accuracy: 0.0316 - val_loss: 1.7236 - val_accuracy: 0.0200\n",
      "Epoch 137/600\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 1.0812 - accuracy: 0.0317 - val_loss: 1.7212 - val_accuracy: 0.0192\n",
      "Epoch 138/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.0807 - accuracy: 0.0326 - val_loss: 1.7230 - val_accuracy: 0.0205\n",
      "Epoch 139/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.0809 - accuracy: 0.0318 - val_loss: 1.7096 - val_accuracy: 0.0203\n",
      "Epoch 140/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.0803 - accuracy: 0.0321 - val_loss: 1.7168 - val_accuracy: 0.0188\n",
      "Epoch 141/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.0771 - accuracy: 0.0324 - val_loss: 1.7137 - val_accuracy: 0.0198\n",
      "Epoch 142/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.0777 - accuracy: 0.0316 - val_loss: 1.7084 - val_accuracy: 0.0205\n",
      "Epoch 143/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.0755 - accuracy: 0.0323 - val_loss: 1.7280 - val_accuracy: 0.0195\n",
      "Epoch 144/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.0744 - accuracy: 0.0322 - val_loss: 1.7095 - val_accuracy: 0.0205\n",
      "Epoch 145/600\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 1.0740 - accuracy: 0.0321 - val_loss: 1.7082 - val_accuracy: 0.0205\n",
      "Epoch 146/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.0750 - accuracy: 0.0324 - val_loss: 1.7233 - val_accuracy: 0.0192\n",
      "Epoch 147/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.0719 - accuracy: 0.0332 - val_loss: 1.7188 - val_accuracy: 0.0195\n",
      "Epoch 148/600\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.0699 - accuracy: 0.0334 - val_loss: 1.7225 - val_accuracy: 0.0192\n",
      "Epoch 149/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.0708 - accuracy: 0.0333 - val_loss: 1.7171 - val_accuracy: 0.0205\n",
      "Epoch 150/600\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.0668 - accuracy: 0.0330 - val_loss: 1.7214 - val_accuracy: 0.0198\n",
      "Epoch 151/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.0656 - accuracy: 0.0326 - val_loss: 1.7116 - val_accuracy: 0.0200\n",
      "Epoch 152/600\n",
      "32/32 [==============================] - 13s 418ms/step - loss: 1.0677 - accuracy: 0.0333 - val_loss: 1.7347 - val_accuracy: 0.0200\n",
      "Epoch 153/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.1095 - accuracy: 0.0304 - val_loss: 1.7126 - val_accuracy: 0.0213\n",
      "Epoch 154/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.0903 - accuracy: 0.0310 - val_loss: 1.7045 - val_accuracy: 0.0192\n",
      "Epoch 155/600\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 1.0748 - accuracy: 0.0321 - val_loss: 1.7156 - val_accuracy: 0.0195\n",
      "Epoch 156/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.0803 - accuracy: 0.0322 - val_loss: 1.7080 - val_accuracy: 0.0195\n",
      "Epoch 157/600\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.0733 - accuracy: 0.0318 - val_loss: 1.7267 - val_accuracy: 0.0203\n",
      "Epoch 158/600\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.1125 - accuracy: 0.0286 - val_loss: 1.6976 - val_accuracy: 0.0198\n",
      "Epoch 159/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.0792 - accuracy: 0.0321 - val_loss: 1.7125 - val_accuracy: 0.0180\n",
      "Epoch 160/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.0709 - accuracy: 0.0327 - val_loss: 1.7226 - val_accuracy: 0.0185\n",
      "Epoch 161/600\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.0651 - accuracy: 0.0329 - val_loss: 1.7292 - val_accuracy: 0.0198\n",
      "Epoch 162/600\n",
      "32/32 [==============================] - 13s 416ms/step - loss: 1.0703 - accuracy: 0.0342 - val_loss: 1.7086 - val_accuracy: 0.0192\n",
      "Epoch 163/600\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 1.0617 - accuracy: 0.0338 - val_loss: 1.7175 - val_accuracy: 0.0203\n",
      "Epoch 164/600\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 1.0619 - accuracy: 0.0341 - val_loss: 1.7159 - val_accuracy: 0.0200\n",
      "Epoch 165/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.0581 - accuracy: 0.0344 - val_loss: 1.7101 - val_accuracy: 0.0185\n",
      "Epoch 166/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.0599 - accuracy: 0.0344 - val_loss: 1.7174 - val_accuracy: 0.0190\n",
      "Epoch 167/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.0566 - accuracy: 0.0348 - val_loss: 1.7137 - val_accuracy: 0.0192\n",
      "Epoch 168/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.0540 - accuracy: 0.0339 - val_loss: 1.7236 - val_accuracy: 0.0210\n",
      "Epoch 169/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 13s 411ms/step - loss: 1.0538 - accuracy: 0.0347 - val_loss: 1.7208 - val_accuracy: 0.0188\n",
      "Epoch 170/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.0536 - accuracy: 0.0352 - val_loss: 1.7173 - val_accuracy: 0.0192\n",
      "Epoch 171/600\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 1.0513 - accuracy: 0.0350 - val_loss: 1.7155 - val_accuracy: 0.0203\n",
      "Epoch 172/600\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.1100 - accuracy: 0.0281 - val_loss: 1.6764 - val_accuracy: 0.0198\n",
      "Epoch 173/600\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 1.1145 - accuracy: 0.0286 - val_loss: 1.6782 - val_accuracy: 0.0205\n",
      "Epoch 174/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.0998 - accuracy: 0.0309 - val_loss: 1.6867 - val_accuracy: 0.0205\n",
      "Epoch 175/600\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 1.0816 - accuracy: 0.0321 - val_loss: 1.6919 - val_accuracy: 0.0205\n",
      "Epoch 176/600\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 1.0729 - accuracy: 0.0333 - val_loss: 1.6876 - val_accuracy: 0.0210\n",
      "Epoch 177/600\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 1.1044 - accuracy: 0.0301 - val_loss: 1.6855 - val_accuracy: 0.0205\n",
      "Epoch 178/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 1.1000 - accuracy: 0.0312 - val_loss: 1.6888 - val_accuracy: 0.0210\n",
      "Epoch 179/600\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 1.0935 - accuracy: 0.0309 - val_loss: 1.6881 - val_accuracy: 0.0213\n",
      "Epoch 180/600\n",
      "32/32 [==============================] - 13s 397ms/step - loss: 1.0883 - accuracy: 0.0316 - val_loss: 1.6912 - val_accuracy: 0.0217\n",
      "Epoch 181/600\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 1.0951 - accuracy: 0.0302 - val_loss: 1.7009 - val_accuracy: 0.0213\n",
      "Epoch 182/600\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 1.0754 - accuracy: 0.0324 - val_loss: 1.6961 - val_accuracy: 0.0213\n",
      "Epoch 183/600\n",
      "32/32 [==============================] - 14s 421ms/step - loss: 1.0795 - accuracy: 0.0325 - val_loss: 1.7183 - val_accuracy: 0.0205\n",
      "Epoch 184/600\n",
      "32/32 [==============================] - 12s 387ms/step - loss: 1.0677 - accuracy: 0.0329 - val_loss: 1.7193 - val_accuracy: 0.0215\n",
      "Epoch 185/600\n",
      "32/32 [==============================] - 12s 383ms/step - loss: 1.0655 - accuracy: 0.0337 - val_loss: 1.7079 - val_accuracy: 0.0198\n",
      "Epoch 186/600\n",
      "32/32 [==============================] - 12s 379ms/step - loss: 1.0607 - accuracy: 0.0334 - val_loss: 1.7167 - val_accuracy: 0.0207\n",
      "Epoch 187/600\n",
      "32/32 [==============================] - 13s 395ms/step - loss: 1.0559 - accuracy: 0.0344 - val_loss: 1.7077 - val_accuracy: 0.0217\n",
      "Epoch 188/600\n",
      "32/32 [==============================] - 13s 418ms/step - loss: 1.0614 - accuracy: 0.0334 - val_loss: 1.7131 - val_accuracy: 0.0210\n",
      "Epoch 189/600\n",
      "32/32 [==============================] - 13s 400ms/step - loss: 1.0545 - accuracy: 0.0351 - val_loss: 1.7166 - val_accuracy: 0.0200\n",
      "Epoch 190/600\n",
      "32/32 [==============================] - 13s 392ms/step - loss: 1.0678 - accuracy: 0.0331 - val_loss: 1.7027 - val_accuracy: 0.0210\n",
      "Epoch 191/600\n",
      "32/32 [==============================] - 13s 396ms/step - loss: 1.0510 - accuracy: 0.0349 - val_loss: 1.7273 - val_accuracy: 0.0207\n",
      "Epoch 192/600\n",
      "32/32 [==============================] - 13s 396ms/step - loss: 1.0485 - accuracy: 0.0351 - val_loss: 1.7088 - val_accuracy: 0.0205\n",
      "Epoch 193/600\n",
      "32/32 [==============================] - 13s 398ms/step - loss: 1.0455 - accuracy: 0.0353 - val_loss: 1.6999 - val_accuracy: 0.0203\n",
      "Epoch 194/600\n",
      "32/32 [==============================] - 13s 397ms/step - loss: 1.0470 - accuracy: 0.0354 - val_loss: 1.7039 - val_accuracy: 0.0223\n",
      "Epoch 195/600\n",
      "32/32 [==============================] - 13s 403ms/step - loss: 1.0452 - accuracy: 0.0352 - val_loss: 1.7081 - val_accuracy: 0.0207\n",
      "Epoch 196/600\n",
      "32/32 [==============================] - 13s 400ms/step - loss: 1.0437 - accuracy: 0.0347 - val_loss: 1.7113 - val_accuracy: 0.0213\n",
      "Epoch 197/600\n",
      "32/32 [==============================] - 12s 388ms/step - loss: 1.0415 - accuracy: 0.0364 - val_loss: 1.7079 - val_accuracy: 0.0210\n",
      "Epoch 198/600\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 1.0398 - accuracy: 0.0363 - val_loss: 1.7037 - val_accuracy: 0.0210\n",
      "Epoch 199/600\n",
      "32/32 [==============================] - 13s 397ms/step - loss: 1.0375 - accuracy: 0.0367 - val_loss: 1.7116 - val_accuracy: 0.0205\n",
      "Epoch 200/600\n",
      "32/32 [==============================] - 14s 427ms/step - loss: 1.0367 - accuracy: 0.0359 - val_loss: 1.7094 - val_accuracy: 0.0203\n",
      "Epoch 201/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 1.0373 - accuracy: 0.0362 - val_loss: 1.7085 - val_accuracy: 0.0215\n",
      "Epoch 202/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 1.0342 - accuracy: 0.0366 - val_loss: 1.7027 - val_accuracy: 0.0207\n",
      "Epoch 203/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 1.0353 - accuracy: 0.0365 - val_loss: 1.7039 - val_accuracy: 0.0203\n",
      "Epoch 204/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 1.0321 - accuracy: 0.0375 - val_loss: 1.7150 - val_accuracy: 0.0213\n",
      "Epoch 205/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 1.0318 - accuracy: 0.0371 - val_loss: 1.7151 - val_accuracy: 0.0203\n",
      "Epoch 206/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 1.0296 - accuracy: 0.0376 - val_loss: 1.6946 - val_accuracy: 0.0205\n",
      "Epoch 207/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 1.0301 - accuracy: 0.0376 - val_loss: 1.7126 - val_accuracy: 0.0213\n",
      "Epoch 208/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 1.0275 - accuracy: 0.0377 - val_loss: 1.7103 - val_accuracy: 0.0210\n",
      "Epoch 209/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 1.0261 - accuracy: 0.0386 - val_loss: 1.7060 - val_accuracy: 0.0207\n",
      "Epoch 210/600\n",
      "32/32 [==============================] - 13s 423ms/step - loss: 1.0233 - accuracy: 0.0383 - val_loss: 1.7152 - val_accuracy: 0.0213\n",
      "Epoch 211/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 1.0195 - accuracy: 0.0388 - val_loss: 1.7135 - val_accuracy: 0.0203\n",
      "Epoch 212/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 1.0202 - accuracy: 0.0388 - val_loss: 1.7134 - val_accuracy: 0.0198\n",
      "Epoch 213/600\n",
      "32/32 [==============================] - 14s 425ms/step - loss: 1.0173 - accuracy: 0.0384 - val_loss: 1.7018 - val_accuracy: 0.0207\n",
      "Epoch 214/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 1.0188 - accuracy: 0.0394 - val_loss: 1.7039 - val_accuracy: 0.0207\n",
      "Epoch 215/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 1.0164 - accuracy: 0.0394 - val_loss: 1.7049 - val_accuracy: 0.0210\n",
      "Epoch 216/600\n",
      "32/32 [==============================] - 13s 423ms/step - loss: 1.0181 - accuracy: 0.0385 - val_loss: 1.7173 - val_accuracy: 0.0213\n",
      "Epoch 217/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 1.0121 - accuracy: 0.0399 - val_loss: 1.7103 - val_accuracy: 0.0205\n",
      "Epoch 218/600\n",
      "32/32 [==============================] - 14s 430ms/step - loss: 1.0113 - accuracy: 0.0407 - val_loss: 1.7143 - val_accuracy: 0.0207\n",
      "Epoch 219/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 1.0095 - accuracy: 0.0403 - val_loss: 1.7130 - val_accuracy: 0.0220\n",
      "Epoch 220/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 1.0069 - accuracy: 0.0414 - val_loss: 1.7115 - val_accuracy: 0.0215\n",
      "Epoch 221/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 1.0053 - accuracy: 0.0417 - val_loss: 1.7173 - val_accuracy: 0.0200\n",
      "Epoch 222/600\n",
      "32/32 [==============================] - 14s 427ms/step - loss: 1.0079 - accuracy: 0.0405 - val_loss: 1.7121 - val_accuracy: 0.0207\n",
      "Epoch 223/600\n",
      "32/32 [==============================] - 14s 430ms/step - loss: 1.0052 - accuracy: 0.0413 - val_loss: 1.7112 - val_accuracy: 0.0210\n",
      "Epoch 224/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 1.0016 - accuracy: 0.0424 - val_loss: 1.7216 - val_accuracy: 0.0215\n",
      "Epoch 225/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 14s 423ms/step - loss: 0.9997 - accuracy: 0.0424 - val_loss: 1.7114 - val_accuracy: 0.0207\n",
      "Epoch 226/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 1.0003 - accuracy: 0.0425 - val_loss: 1.7061 - val_accuracy: 0.0205\n",
      "Epoch 227/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.9936 - accuracy: 0.0435 - val_loss: 1.7092 - val_accuracy: 0.0200\n",
      "Epoch 228/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.9943 - accuracy: 0.0438 - val_loss: 1.7132 - val_accuracy: 0.0203\n",
      "Epoch 229/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.9950 - accuracy: 0.0426 - val_loss: 1.7085 - val_accuracy: 0.0205\n",
      "Epoch 230/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.9924 - accuracy: 0.0428 - val_loss: 1.7125 - val_accuracy: 0.0203\n",
      "Epoch 231/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.9899 - accuracy: 0.0444 - val_loss: 1.7095 - val_accuracy: 0.0203\n",
      "Epoch 232/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.9899 - accuracy: 0.0437 - val_loss: 1.7156 - val_accuracy: 0.0213\n",
      "Epoch 233/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.9952 - accuracy: 0.0434 - val_loss: 1.7125 - val_accuracy: 0.0207\n",
      "Epoch 234/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.9875 - accuracy: 0.0443 - val_loss: 1.7116 - val_accuracy: 0.0195\n",
      "Epoch 235/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.9843 - accuracy: 0.0443 - val_loss: 1.7091 - val_accuracy: 0.0200\n",
      "Epoch 236/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.9835 - accuracy: 0.0448 - val_loss: 1.7219 - val_accuracy: 0.0198\n",
      "Epoch 237/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.9850 - accuracy: 0.0456 - val_loss: 1.7159 - val_accuracy: 0.0207\n",
      "Epoch 238/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.9816 - accuracy: 0.0458 - val_loss: 1.7210 - val_accuracy: 0.0203\n",
      "Epoch 239/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.9778 - accuracy: 0.0464 - val_loss: 1.7105 - val_accuracy: 0.0200\n",
      "Epoch 240/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.9781 - accuracy: 0.0455 - val_loss: 1.7204 - val_accuracy: 0.0203\n",
      "Epoch 241/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.9755 - accuracy: 0.0471 - val_loss: 1.7092 - val_accuracy: 0.0205\n",
      "Epoch 242/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.9749 - accuracy: 0.0463 - val_loss: 1.7155 - val_accuracy: 0.0210\n",
      "Epoch 243/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.9741 - accuracy: 0.0476 - val_loss: 1.7185 - val_accuracy: 0.0205\n",
      "Epoch 244/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.9692 - accuracy: 0.0480 - val_loss: 1.7149 - val_accuracy: 0.0203\n",
      "Epoch 245/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.9704 - accuracy: 0.0469 - val_loss: 1.7105 - val_accuracy: 0.0205\n",
      "Epoch 246/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.9679 - accuracy: 0.0478 - val_loss: 1.7188 - val_accuracy: 0.0192\n",
      "Epoch 247/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.9703 - accuracy: 0.0472 - val_loss: 1.7161 - val_accuracy: 0.0200\n",
      "Epoch 248/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.9626 - accuracy: 0.0482 - val_loss: 1.7285 - val_accuracy: 0.0200\n",
      "Epoch 249/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.9639 - accuracy: 0.0494 - val_loss: 1.7247 - val_accuracy: 0.0195\n",
      "Epoch 250/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.9621 - accuracy: 0.0488 - val_loss: 1.7249 - val_accuracy: 0.0210\n",
      "Epoch 251/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.9598 - accuracy: 0.0492 - val_loss: 1.7244 - val_accuracy: 0.0200\n",
      "Epoch 252/600\n",
      "32/32 [==============================] - 14s 425ms/step - loss: 0.9595 - accuracy: 0.0494 - val_loss: 1.7161 - val_accuracy: 0.0203\n",
      "Epoch 253/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.9559 - accuracy: 0.0494 - val_loss: 1.7133 - val_accuracy: 0.0203\n",
      "Epoch 254/600\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 0.9536 - accuracy: 0.0499 - val_loss: 1.7160 - val_accuracy: 0.0205\n",
      "Epoch 255/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.9517 - accuracy: 0.0506 - val_loss: 1.7192 - val_accuracy: 0.0200\n",
      "Epoch 256/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.9501 - accuracy: 0.0509 - val_loss: 1.7223 - val_accuracy: 0.0195\n",
      "Epoch 257/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.9472 - accuracy: 0.0511 - val_loss: 1.7198 - val_accuracy: 0.0203\n",
      "Epoch 258/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.9430 - accuracy: 0.0516 - val_loss: 1.7150 - val_accuracy: 0.0200\n",
      "Epoch 259/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.9459 - accuracy: 0.0512 - val_loss: 1.7155 - val_accuracy: 0.0198\n",
      "Epoch 260/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.9485 - accuracy: 0.0507 - val_loss: 1.7210 - val_accuracy: 0.0207\n",
      "Epoch 261/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.9454 - accuracy: 0.0518 - val_loss: 1.7295 - val_accuracy: 0.0198\n",
      "Epoch 262/600\n",
      "32/32 [==============================] - 14s 425ms/step - loss: 0.9420 - accuracy: 0.0534 - val_loss: 1.7270 - val_accuracy: 0.0195\n",
      "Epoch 263/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.9392 - accuracy: 0.0528 - val_loss: 1.7222 - val_accuracy: 0.0198\n",
      "Epoch 264/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.9430 - accuracy: 0.0524 - val_loss: 1.7178 - val_accuracy: 0.0213\n",
      "Epoch 265/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.9487 - accuracy: 0.0516 - val_loss: 1.7246 - val_accuracy: 0.0200\n",
      "Epoch 266/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.9361 - accuracy: 0.0534 - val_loss: 1.7198 - val_accuracy: 0.0198\n",
      "Epoch 267/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.9381 - accuracy: 0.0527 - val_loss: 1.7364 - val_accuracy: 0.0200\n",
      "Epoch 268/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.9373 - accuracy: 0.0523 - val_loss: 1.7192 - val_accuracy: 0.0205\n",
      "Epoch 269/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.9345 - accuracy: 0.0531 - val_loss: 1.7216 - val_accuracy: 0.0200\n",
      "Epoch 270/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.9331 - accuracy: 0.0541 - val_loss: 1.7266 - val_accuracy: 0.0195\n",
      "Epoch 271/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.9319 - accuracy: 0.0543 - val_loss: 1.7202 - val_accuracy: 0.0207\n",
      "Epoch 272/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.9246 - accuracy: 0.0538 - val_loss: 1.7289 - val_accuracy: 0.0205\n",
      "Epoch 273/600\n",
      "32/32 [==============================] - 13s 423ms/step - loss: 0.9285 - accuracy: 0.0549 - val_loss: 1.7238 - val_accuracy: 0.0207\n",
      "Epoch 274/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.9218 - accuracy: 0.0556 - val_loss: 1.7325 - val_accuracy: 0.0188\n",
      "Epoch 275/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.9242 - accuracy: 0.0562 - val_loss: 1.7278 - val_accuracy: 0.0203\n",
      "Epoch 276/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.9259 - accuracy: 0.0549 - val_loss: 1.7228 - val_accuracy: 0.0200\n",
      "Epoch 277/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.9185 - accuracy: 0.0570 - val_loss: 1.7194 - val_accuracy: 0.0203\n",
      "Epoch 278/600\n",
      "32/32 [==============================] - 13s 418ms/step - loss: 0.9174 - accuracy: 0.0569 - val_loss: 1.7231 - val_accuracy: 0.0205\n",
      "Epoch 279/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.9114 - accuracy: 0.0576 - val_loss: 1.7222 - val_accuracy: 0.0205\n",
      "Epoch 280/600\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 0.9130 - accuracy: 0.0565 - val_loss: 1.7399 - val_accuracy: 0.0203\n",
      "Epoch 281/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 13s 420ms/step - loss: 0.9047 - accuracy: 0.0587 - val_loss: 1.7301 - val_accuracy: 0.0213\n",
      "Epoch 282/600\n",
      "32/32 [==============================] - 13s 423ms/step - loss: 0.9115 - accuracy: 0.0578 - val_loss: 1.7252 - val_accuracy: 0.0203\n",
      "Epoch 283/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.9104 - accuracy: 0.0581 - val_loss: 1.7192 - val_accuracy: 0.0198\n",
      "Epoch 284/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.9021 - accuracy: 0.0596 - val_loss: 1.7251 - val_accuracy: 0.0205\n",
      "Epoch 285/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.9079 - accuracy: 0.0584 - val_loss: 1.7343 - val_accuracy: 0.0200\n",
      "Epoch 286/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.9019 - accuracy: 0.0589 - val_loss: 1.7243 - val_accuracy: 0.0213\n",
      "Epoch 287/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.8984 - accuracy: 0.0596 - val_loss: 1.7233 - val_accuracy: 0.0207\n",
      "Epoch 288/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.8982 - accuracy: 0.0596 - val_loss: 1.7258 - val_accuracy: 0.0200\n",
      "Epoch 289/600\n",
      "32/32 [==============================] - 13s 416ms/step - loss: 0.8967 - accuracy: 0.0599 - val_loss: 1.7173 - val_accuracy: 0.0195\n",
      "Epoch 290/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.8937 - accuracy: 0.0608 - val_loss: 1.7319 - val_accuracy: 0.0190\n",
      "Epoch 291/600\n",
      "32/32 [==============================] - 14s 433ms/step - loss: 0.8977 - accuracy: 0.0591 - val_loss: 1.7162 - val_accuracy: 0.0210\n",
      "Epoch 292/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8949 - accuracy: 0.0596 - val_loss: 1.7281 - val_accuracy: 0.0207\n",
      "Epoch 293/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8935 - accuracy: 0.0599 - val_loss: 1.7238 - val_accuracy: 0.0200\n",
      "Epoch 294/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8872 - accuracy: 0.0608 - val_loss: 1.7289 - val_accuracy: 0.0203\n",
      "Epoch 295/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.8862 - accuracy: 0.0609 - val_loss: 1.7302 - val_accuracy: 0.0203\n",
      "Epoch 296/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8877 - accuracy: 0.0622 - val_loss: 1.7401 - val_accuracy: 0.0200\n",
      "Epoch 297/600\n",
      "32/32 [==============================] - 13s 423ms/step - loss: 0.8858 - accuracy: 0.0614 - val_loss: 1.7221 - val_accuracy: 0.0205\n",
      "Epoch 298/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8752 - accuracy: 0.0631 - val_loss: 1.7201 - val_accuracy: 0.0198\n",
      "Epoch 299/600\n",
      "32/32 [==============================] - 13s 423ms/step - loss: 0.8797 - accuracy: 0.0629 - val_loss: 1.7208 - val_accuracy: 0.0215\n",
      "Epoch 300/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8722 - accuracy: 0.0642 - val_loss: 1.7278 - val_accuracy: 0.0203\n",
      "Epoch 301/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8766 - accuracy: 0.0627 - val_loss: 1.7354 - val_accuracy: 0.0198\n",
      "Epoch 302/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8736 - accuracy: 0.0634 - val_loss: 1.7343 - val_accuracy: 0.0200\n",
      "Epoch 303/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8743 - accuracy: 0.0638 - val_loss: 1.7374 - val_accuracy: 0.0198\n",
      "Epoch 304/600\n",
      "32/32 [==============================] - 13s 418ms/step - loss: 0.8669 - accuracy: 0.0648 - val_loss: 1.7320 - val_accuracy: 0.0192\n",
      "Epoch 305/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8750 - accuracy: 0.0638 - val_loss: 1.7282 - val_accuracy: 0.0200\n",
      "Epoch 306/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8686 - accuracy: 0.0637 - val_loss: 1.7393 - val_accuracy: 0.0190\n",
      "Epoch 307/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.8686 - accuracy: 0.0646 - val_loss: 1.7180 - val_accuracy: 0.0200\n",
      "Epoch 308/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8684 - accuracy: 0.0655 - val_loss: 1.7297 - val_accuracy: 0.0198\n",
      "Epoch 309/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8560 - accuracy: 0.0663 - val_loss: 1.7354 - val_accuracy: 0.0203\n",
      "Epoch 310/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8574 - accuracy: 0.0679 - val_loss: 1.7454 - val_accuracy: 0.0210\n",
      "Epoch 311/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8592 - accuracy: 0.0671 - val_loss: 1.7236 - val_accuracy: 0.0190\n",
      "Epoch 312/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.8557 - accuracy: 0.0661 - val_loss: 1.7304 - val_accuracy: 0.0200\n",
      "Epoch 313/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8599 - accuracy: 0.0660 - val_loss: 1.7352 - val_accuracy: 0.0210\n",
      "Epoch 314/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8587 - accuracy: 0.0667 - val_loss: 1.7314 - val_accuracy: 0.0223\n",
      "Epoch 315/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8626 - accuracy: 0.0656 - val_loss: 1.7374 - val_accuracy: 0.0200\n",
      "Epoch 316/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.8495 - accuracy: 0.0677 - val_loss: 1.7381 - val_accuracy: 0.0203\n",
      "Epoch 317/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8452 - accuracy: 0.0691 - val_loss: 1.7399 - val_accuracy: 0.0198\n",
      "Epoch 318/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.8496 - accuracy: 0.0668 - val_loss: 1.7414 - val_accuracy: 0.0213\n",
      "Epoch 319/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8518 - accuracy: 0.0676 - val_loss: 1.7397 - val_accuracy: 0.0203\n",
      "Epoch 320/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.8420 - accuracy: 0.0691 - val_loss: 1.7348 - val_accuracy: 0.0190\n",
      "Epoch 321/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.8431 - accuracy: 0.0696 - val_loss: 1.7335 - val_accuracy: 0.0198\n",
      "Epoch 322/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.8395 - accuracy: 0.0692 - val_loss: 1.7446 - val_accuracy: 0.0210\n",
      "Epoch 323/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.8436 - accuracy: 0.0685 - val_loss: 1.7459 - val_accuracy: 0.0195\n",
      "Epoch 324/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.8378 - accuracy: 0.0713 - val_loss: 1.7451 - val_accuracy: 0.0205\n",
      "Epoch 325/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8364 - accuracy: 0.0702 - val_loss: 1.7320 - val_accuracy: 0.0200\n",
      "Epoch 326/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8309 - accuracy: 0.0724 - val_loss: 1.7322 - val_accuracy: 0.0215\n",
      "Epoch 327/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.8288 - accuracy: 0.0706 - val_loss: 1.7491 - val_accuracy: 0.0203\n",
      "Epoch 328/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8280 - accuracy: 0.0711 - val_loss: 1.7469 - val_accuracy: 0.0207\n",
      "Epoch 329/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8295 - accuracy: 0.0714 - val_loss: 1.7390 - val_accuracy: 0.0200\n",
      "Epoch 330/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8266 - accuracy: 0.0719 - val_loss: 1.7447 - val_accuracy: 0.0198\n",
      "Epoch 331/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8232 - accuracy: 0.0721 - val_loss: 1.7521 - val_accuracy: 0.0210\n",
      "Epoch 332/600\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 0.8215 - accuracy: 0.0734 - val_loss: 1.7473 - val_accuracy: 0.0207\n",
      "Epoch 333/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.8193 - accuracy: 0.0742 - val_loss: 1.7381 - val_accuracy: 0.0207\n",
      "Epoch 334/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.8244 - accuracy: 0.0724 - val_loss: 1.7458 - val_accuracy: 0.0207\n",
      "Epoch 335/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8150 - accuracy: 0.0738 - val_loss: 1.7508 - val_accuracy: 0.0203\n",
      "Epoch 336/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.8144 - accuracy: 0.0748 - val_loss: 1.7541 - val_accuracy: 0.0205\n",
      "Epoch 337/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 13s 423ms/step - loss: 0.8182 - accuracy: 0.0746 - val_loss: 1.7278 - val_accuracy: 0.0210\n",
      "Epoch 338/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.8165 - accuracy: 0.0736 - val_loss: 1.7402 - val_accuracy: 0.0213\n",
      "Epoch 339/600\n",
      "32/32 [==============================] - 13s 423ms/step - loss: 0.8078 - accuracy: 0.0759 - val_loss: 1.7458 - val_accuracy: 0.0195\n",
      "Epoch 340/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8143 - accuracy: 0.0741 - val_loss: 1.7427 - val_accuracy: 0.0188\n",
      "Epoch 341/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8044 - accuracy: 0.0768 - val_loss: 1.7339 - val_accuracy: 0.0198\n",
      "Epoch 342/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.8200 - accuracy: 0.0733 - val_loss: 1.7446 - val_accuracy: 0.0198\n",
      "Epoch 343/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8032 - accuracy: 0.0771 - val_loss: 1.7571 - val_accuracy: 0.0198\n",
      "Epoch 344/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8024 - accuracy: 0.0768 - val_loss: 1.7549 - val_accuracy: 0.0198\n",
      "Epoch 345/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.8070 - accuracy: 0.0763 - val_loss: 1.7573 - val_accuracy: 0.0207\n",
      "Epoch 346/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8014 - accuracy: 0.0775 - val_loss: 1.7504 - val_accuracy: 0.0205\n",
      "Epoch 347/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.8004 - accuracy: 0.0764 - val_loss: 1.7565 - val_accuracy: 0.0203\n",
      "Epoch 348/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.7981 - accuracy: 0.0776 - val_loss: 1.7519 - val_accuracy: 0.0200\n",
      "Epoch 349/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7977 - accuracy: 0.0777 - val_loss: 1.7496 - val_accuracy: 0.0203\n",
      "Epoch 350/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.7908 - accuracy: 0.0777 - val_loss: 1.7527 - val_accuracy: 0.0190\n",
      "Epoch 351/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7969 - accuracy: 0.0764 - val_loss: 1.7568 - val_accuracy: 0.0203\n",
      "Epoch 352/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.7929 - accuracy: 0.0787 - val_loss: 1.7495 - val_accuracy: 0.0200\n",
      "Epoch 353/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.7885 - accuracy: 0.0796 - val_loss: 1.7395 - val_accuracy: 0.0200\n",
      "Epoch 354/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.7892 - accuracy: 0.0793 - val_loss: 1.7479 - val_accuracy: 0.0217\n",
      "Epoch 355/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.7886 - accuracy: 0.0781 - val_loss: 1.7514 - val_accuracy: 0.0207\n",
      "Epoch 356/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.7860 - accuracy: 0.0803 - val_loss: 1.7574 - val_accuracy: 0.0205\n",
      "Epoch 357/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.7853 - accuracy: 0.0796 - val_loss: 1.7439 - val_accuracy: 0.0215\n",
      "Epoch 358/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.7818 - accuracy: 0.0800 - val_loss: 1.7498 - val_accuracy: 0.0205\n",
      "Epoch 359/600\n",
      "32/32 [==============================] - 14s 425ms/step - loss: 0.7945 - accuracy: 0.0798 - val_loss: 1.7566 - val_accuracy: 0.0200\n",
      "Epoch 360/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.7723 - accuracy: 0.0825 - val_loss: 1.7650 - val_accuracy: 0.0195\n",
      "Epoch 361/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.7773 - accuracy: 0.0820 - val_loss: 1.7589 - val_accuracy: 0.0210\n",
      "Epoch 362/600\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 0.7715 - accuracy: 0.0821 - val_loss: 1.7545 - val_accuracy: 0.0207\n",
      "Epoch 363/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.7771 - accuracy: 0.0804 - val_loss: 1.7387 - val_accuracy: 0.0200\n",
      "Epoch 364/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.7802 - accuracy: 0.0794 - val_loss: 1.7627 - val_accuracy: 0.0195\n",
      "Epoch 365/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.7690 - accuracy: 0.0833 - val_loss: 1.7632 - val_accuracy: 0.0203\n",
      "Epoch 366/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7718 - accuracy: 0.0826 - val_loss: 1.7516 - val_accuracy: 0.0210\n",
      "Epoch 367/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.7700 - accuracy: 0.0829 - val_loss: 1.7649 - val_accuracy: 0.0207\n",
      "Epoch 368/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7921 - accuracy: 0.0779 - val_loss: 1.7740 - val_accuracy: 0.0198\n",
      "Epoch 369/600\n",
      "32/32 [==============================] - 13s 418ms/step - loss: 0.7818 - accuracy: 0.0799 - val_loss: 1.7475 - val_accuracy: 0.0203\n",
      "Epoch 370/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7826 - accuracy: 0.0808 - val_loss: 1.7627 - val_accuracy: 0.0200\n",
      "Epoch 371/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.7650 - accuracy: 0.0841 - val_loss: 1.7601 - val_accuracy: 0.0203\n",
      "Epoch 372/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.7586 - accuracy: 0.0853 - val_loss: 1.7614 - val_accuracy: 0.0195\n",
      "Epoch 373/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.7641 - accuracy: 0.0833 - val_loss: 1.7541 - val_accuracy: 0.0205\n",
      "Epoch 374/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.7653 - accuracy: 0.0834 - val_loss: 1.7504 - val_accuracy: 0.0210\n",
      "Epoch 375/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.7593 - accuracy: 0.0849 - val_loss: 1.7460 - val_accuracy: 0.0203\n",
      "Epoch 376/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.7631 - accuracy: 0.0844 - val_loss: 1.7548 - val_accuracy: 0.0205\n",
      "Epoch 377/600\n",
      "32/32 [==============================] - 14s 427ms/step - loss: 0.7545 - accuracy: 0.0851 - val_loss: 1.7522 - val_accuracy: 0.0205\n",
      "Epoch 378/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.7713 - accuracy: 0.0826 - val_loss: 1.7444 - val_accuracy: 0.0210\n",
      "Epoch 379/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.7680 - accuracy: 0.0836 - val_loss: 1.7451 - val_accuracy: 0.0207\n",
      "Epoch 380/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.7543 - accuracy: 0.0858 - val_loss: 1.7443 - val_accuracy: 0.0207\n",
      "Epoch 381/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7579 - accuracy: 0.0847 - val_loss: 1.7531 - val_accuracy: 0.0200\n",
      "Epoch 382/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7632 - accuracy: 0.0828 - val_loss: 1.7458 - val_accuracy: 0.0210\n",
      "Epoch 383/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7466 - accuracy: 0.0863 - val_loss: 1.7585 - val_accuracy: 0.0203\n",
      "Epoch 384/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.7478 - accuracy: 0.0869 - val_loss: 1.7412 - val_accuracy: 0.0200\n",
      "Epoch 385/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.7426 - accuracy: 0.0865 - val_loss: 1.7493 - val_accuracy: 0.0207\n",
      "Epoch 386/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7438 - accuracy: 0.0866 - val_loss: 1.7451 - val_accuracy: 0.0192\n",
      "Epoch 387/600\n",
      "32/32 [==============================] - 14s 425ms/step - loss: 0.7446 - accuracy: 0.0866 - val_loss: 1.7663 - val_accuracy: 0.0205\n",
      "Epoch 388/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7395 - accuracy: 0.0882 - val_loss: 1.7623 - val_accuracy: 0.0188\n",
      "Epoch 389/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.7379 - accuracy: 0.0890 - val_loss: 1.7665 - val_accuracy: 0.0200\n",
      "Epoch 390/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7393 - accuracy: 0.0869 - val_loss: 1.7732 - val_accuracy: 0.0200\n",
      "Epoch 391/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.7346 - accuracy: 0.0881 - val_loss: 1.7733 - val_accuracy: 0.0190\n",
      "Epoch 392/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.7371 - accuracy: 0.0879 - val_loss: 1.7574 - val_accuracy: 0.0200\n",
      "Epoch 393/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 14s 424ms/step - loss: 0.7453 - accuracy: 0.0864 - val_loss: 1.7573 - val_accuracy: 0.0192\n",
      "Epoch 394/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.7313 - accuracy: 0.0903 - val_loss: 1.7612 - val_accuracy: 0.0203\n",
      "Epoch 395/600\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 0.7317 - accuracy: 0.0907 - val_loss: 1.7752 - val_accuracy: 0.0198\n",
      "Epoch 396/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.7286 - accuracy: 0.0891 - val_loss: 1.7567 - val_accuracy: 0.0200\n",
      "Epoch 397/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.7271 - accuracy: 0.0905 - val_loss: 1.7838 - val_accuracy: 0.0195\n",
      "Epoch 398/600\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.7305 - accuracy: 0.0900 - val_loss: 1.7821 - val_accuracy: 0.0198\n",
      "Epoch 399/600\n",
      "32/32 [==============================] - 14s 425ms/step - loss: 0.7246 - accuracy: 0.0908 - val_loss: 1.7498 - val_accuracy: 0.0195\n",
      "Epoch 400/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.7227 - accuracy: 0.0909 - val_loss: 1.7741 - val_accuracy: 0.0190\n",
      "Epoch 401/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.7223 - accuracy: 0.0908 - val_loss: 1.7644 - val_accuracy: 0.0192\n",
      "Epoch 402/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.7192 - accuracy: 0.0916 - val_loss: 1.7549 - val_accuracy: 0.0195\n",
      "Epoch 403/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.7228 - accuracy: 0.0899 - val_loss: 1.7602 - val_accuracy: 0.0203\n",
      "Epoch 404/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.7211 - accuracy: 0.0913 - val_loss: 1.7622 - val_accuracy: 0.0210\n",
      "Epoch 405/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7117 - accuracy: 0.0934 - val_loss: 1.7644 - val_accuracy: 0.0200\n",
      "Epoch 406/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7116 - accuracy: 0.0928 - val_loss: 1.7774 - val_accuracy: 0.0207\n",
      "Epoch 407/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.7223 - accuracy: 0.0904 - val_loss: 1.7659 - val_accuracy: 0.0192\n",
      "Epoch 408/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7122 - accuracy: 0.0940 - val_loss: 1.7692 - val_accuracy: 0.0188\n",
      "Epoch 409/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.7110 - accuracy: 0.0926 - val_loss: 1.7691 - val_accuracy: 0.0200\n",
      "Epoch 410/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.7067 - accuracy: 0.0943 - val_loss: 1.7756 - val_accuracy: 0.0200\n",
      "Epoch 411/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.7111 - accuracy: 0.0933 - val_loss: 1.7785 - val_accuracy: 0.0195\n",
      "Epoch 412/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.7007 - accuracy: 0.0956 - val_loss: 1.7908 - val_accuracy: 0.0192\n",
      "Epoch 413/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7033 - accuracy: 0.0947 - val_loss: 1.7770 - val_accuracy: 0.0207\n",
      "Epoch 414/600\n",
      "32/32 [==============================] - 13s 423ms/step - loss: 0.6980 - accuracy: 0.0957 - val_loss: 1.7814 - val_accuracy: 0.0198\n",
      "Epoch 415/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.6969 - accuracy: 0.0961 - val_loss: 1.7693 - val_accuracy: 0.0192\n",
      "Epoch 416/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.7091 - accuracy: 0.0931 - val_loss: 1.7772 - val_accuracy: 0.0207\n",
      "Epoch 417/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.7170 - accuracy: 0.0902 - val_loss: 1.7802 - val_accuracy: 0.0200\n",
      "Epoch 418/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.6972 - accuracy: 0.0972 - val_loss: 1.7766 - val_accuracy: 0.0190\n",
      "Epoch 419/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.6964 - accuracy: 0.0949 - val_loss: 1.7731 - val_accuracy: 0.0203\n",
      "Epoch 420/600\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.6918 - accuracy: 0.0962 - val_loss: 1.7702 - val_accuracy: 0.0192\n",
      "Epoch 421/600\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.6953 - accuracy: 0.0958 - val_loss: 1.7684 - val_accuracy: 0.0203\n",
      "Epoch 422/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.6939 - accuracy: 0.0963 - val_loss: 1.7701 - val_accuracy: 0.0190\n",
      "Epoch 423/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.6900 - accuracy: 0.0975 - val_loss: 1.7772 - val_accuracy: 0.0205\n",
      "Epoch 424/600\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 0.6835 - accuracy: 0.0989 - val_loss: 1.7648 - val_accuracy: 0.0205\n",
      "Epoch 425/600\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.6916 - accuracy: 0.0982 - val_loss: 1.7688 - val_accuracy: 0.0198\n",
      "Epoch 426/600\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 0.6779 - accuracy: 0.0992 - val_loss: 1.7664 - val_accuracy: 0.0195\n",
      "Epoch 427/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.6815 - accuracy: 0.0993 - val_loss: 1.7767 - val_accuracy: 0.0198\n",
      "Epoch 428/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.6914 - accuracy: 0.0976 - val_loss: 1.7756 - val_accuracy: 0.0185\n",
      "Epoch 429/600\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.6807 - accuracy: 0.0994 - val_loss: 1.7728 - val_accuracy: 0.0185\n",
      "Epoch 430/600\n",
      "32/32 [==============================] - 14s 423ms/step - loss: 0.6805 - accuracy: 0.0988 - val_loss: 1.7727 - val_accuracy: 0.0185\n",
      "Epoch 431/600\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.6811 - accuracy: 0.0984 - val_loss: 1.7866 - val_accuracy: 0.0195\n",
      "Epoch 432/600\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 0.6856 - accuracy: 0.0987 - val_loss: 1.7797 - val_accuracy: 0.0205\n",
      "Epoch 433/600\n",
      "32/32 [==============================] - 13s 399ms/step - loss: 0.6883 - accuracy: 0.0966 - val_loss: 1.7815 - val_accuracy: 0.0205\n",
      "Epoch 434/600\n",
      "32/32 [==============================] - 13s 398ms/step - loss: 0.6765 - accuracy: 0.0998 - val_loss: 1.7914 - val_accuracy: 0.0200\n",
      "Epoch 435/600\n",
      "32/32 [==============================] - 13s 397ms/step - loss: 0.6833 - accuracy: 0.0981 - val_loss: 1.7788 - val_accuracy: 0.0192\n",
      "Epoch 436/600\n",
      "32/32 [==============================] - 12s 381ms/step - loss: 0.6714 - accuracy: 0.1000 - val_loss: 1.7811 - val_accuracy: 0.0190\n",
      "Epoch 437/600\n",
      "32/32 [==============================] - 11s 358ms/step - loss: 0.6724 - accuracy: 0.1001 - val_loss: 1.7649 - val_accuracy: 0.0200\n",
      "Epoch 438/600\n",
      "32/32 [==============================] - 11s 344ms/step - loss: 0.6704 - accuracy: 0.1013 - val_loss: 1.7679 - val_accuracy: 0.0207\n",
      "Epoch 439/600\n",
      "32/32 [==============================] - 11s 332ms/step - loss: 0.6659 - accuracy: 0.1013 - val_loss: 1.7755 - val_accuracy: 0.0195\n",
      "Epoch 440/600\n",
      "32/32 [==============================] - 11s 345ms/step - loss: 0.6699 - accuracy: 0.1015 - val_loss: 1.7715 - val_accuracy: 0.0188\n",
      "Epoch 441/600\n",
      "32/32 [==============================] - 12s 361ms/step - loss: 0.6617 - accuracy: 0.1019 - val_loss: 1.7805 - val_accuracy: 0.0192\n",
      "Epoch 442/600\n",
      "32/32 [==============================] - 11s 358ms/step - loss: 0.6901 - accuracy: 0.0976 - val_loss: 1.7809 - val_accuracy: 0.0198\n",
      "Epoch 443/600\n",
      "32/32 [==============================] - 11s 349ms/step - loss: 0.6688 - accuracy: 0.1017 - val_loss: 1.7801 - val_accuracy: 0.0182\n",
      "Epoch 444/600\n",
      "32/32 [==============================] - 11s 339ms/step - loss: 0.6574 - accuracy: 0.1027 - val_loss: 1.7938 - val_accuracy: 0.0185\n",
      "Epoch 445/600\n",
      "32/32 [==============================] - 11s 342ms/step - loss: 0.6664 - accuracy: 0.1009 - val_loss: 1.7702 - val_accuracy: 0.0213\n",
      "Epoch 446/600\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.6692 - accuracy: 0.1001 - val_loss: 1.7775 - val_accuracy: 0.0210\n",
      "Epoch 447/600\n",
      "32/32 [==============================] - 12s 367ms/step - loss: 0.6630 - accuracy: 0.1014 - val_loss: 1.7877 - val_accuracy: 0.0200\n",
      "Epoch 448/600\n",
      "32/32 [==============================] - 11s 352ms/step - loss: 0.6631 - accuracy: 0.1016 - val_loss: 1.7806 - val_accuracy: 0.0198\n",
      "Epoch 449/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 11s 348ms/step - loss: 0.6571 - accuracy: 0.1033 - val_loss: 1.7855 - val_accuracy: 0.0182\n",
      "Epoch 450/600\n",
      "32/32 [==============================] - 10s 327ms/step - loss: 0.6586 - accuracy: 0.1032 - val_loss: 1.7893 - val_accuracy: 0.0195\n",
      "Epoch 451/600\n",
      "32/32 [==============================] - 11s 345ms/step - loss: 0.6659 - accuracy: 0.1008 - val_loss: 1.7851 - val_accuracy: 0.0200\n",
      "Epoch 452/600\n",
      "32/32 [==============================] - 12s 359ms/step - loss: 0.6529 - accuracy: 0.1037 - val_loss: 1.7811 - val_accuracy: 0.0203\n",
      "Epoch 453/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.6474 - accuracy: 0.1062 - val_loss: 1.7754 - val_accuracy: 0.0205\n",
      "Epoch 454/600\n",
      "32/32 [==============================] - 11s 336ms/step - loss: 0.6529 - accuracy: 0.1029 - val_loss: 1.7809 - val_accuracy: 0.0190\n",
      "Epoch 455/600\n",
      "32/32 [==============================] - 10s 328ms/step - loss: 0.6577 - accuracy: 0.1028 - val_loss: 1.7919 - val_accuracy: 0.0205\n",
      "Epoch 456/600\n",
      "32/32 [==============================] - 11s 347ms/step - loss: 0.6503 - accuracy: 0.1049 - val_loss: 1.7915 - val_accuracy: 0.0195\n",
      "Epoch 457/600\n",
      "32/32 [==============================] - 11s 360ms/step - loss: 0.6465 - accuracy: 0.1053 - val_loss: 1.7863 - val_accuracy: 0.0203\n",
      "Epoch 458/600\n",
      "32/32 [==============================] - 11s 341ms/step - loss: 0.6676 - accuracy: 0.0996 - val_loss: 1.7743 - val_accuracy: 0.0205\n",
      "Epoch 459/600\n",
      "32/32 [==============================] - 11s 339ms/step - loss: 0.6467 - accuracy: 0.1056 - val_loss: 1.7850 - val_accuracy: 0.0207\n",
      "Epoch 460/600\n",
      "32/32 [==============================] - 11s 337ms/step - loss: 0.6390 - accuracy: 0.1064 - val_loss: 1.7833 - val_accuracy: 0.0188\n",
      "Epoch 461/600\n",
      "32/32 [==============================] - 11s 334ms/step - loss: 0.6510 - accuracy: 0.1029 - val_loss: 1.7811 - val_accuracy: 0.0203\n",
      "Epoch 462/600\n",
      "32/32 [==============================] - 11s 336ms/step - loss: 0.6676 - accuracy: 0.1001 - val_loss: 1.7887 - val_accuracy: 0.0205\n",
      "Epoch 463/600\n",
      "32/32 [==============================] - 12s 366ms/step - loss: 0.6390 - accuracy: 0.1059 - val_loss: 1.7738 - val_accuracy: 0.0205\n",
      "Epoch 464/600\n",
      "32/32 [==============================] - 11s 355ms/step - loss: 0.6360 - accuracy: 0.1073 - val_loss: 1.7811 - val_accuracy: 0.0195\n",
      "Epoch 465/600\n",
      "32/32 [==============================] - 10s 329ms/step - loss: 0.6438 - accuracy: 0.1054 - val_loss: 1.7945 - val_accuracy: 0.0203\n",
      "Epoch 466/600\n",
      "32/32 [==============================] - 10s 328ms/step - loss: 0.6451 - accuracy: 0.1059 - val_loss: 1.7890 - val_accuracy: 0.0207\n",
      "Epoch 467/600\n",
      "32/32 [==============================] - 10s 323ms/step - loss: 0.6385 - accuracy: 0.1066 - val_loss: 1.7905 - val_accuracy: 0.0205\n",
      "Epoch 468/600\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.6340 - accuracy: 0.1072 - val_loss: 1.7999 - val_accuracy: 0.0198\n",
      "Epoch 469/600\n",
      "32/32 [==============================] - 10s 323ms/step - loss: 0.6322 - accuracy: 0.1080 - val_loss: 1.7599 - val_accuracy: 0.0190\n",
      "Epoch 470/600\n",
      "32/32 [==============================] - 10s 323ms/step - loss: 0.6412 - accuracy: 0.1066 - val_loss: 1.7948 - val_accuracy: 0.0205\n",
      "Epoch 471/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.6362 - accuracy: 0.1061 - val_loss: 1.7972 - val_accuracy: 0.0198\n",
      "Epoch 472/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.6396 - accuracy: 0.1070 - val_loss: 1.7919 - val_accuracy: 0.0203\n",
      "Epoch 473/600\n",
      "32/32 [==============================] - 11s 332ms/step - loss: 0.6409 - accuracy: 0.1055 - val_loss: 1.7969 - val_accuracy: 0.0198\n",
      "Epoch 474/600\n",
      "32/32 [==============================] - 10s 326ms/step - loss: 0.6394 - accuracy: 0.1066 - val_loss: 1.7915 - val_accuracy: 0.0192\n",
      "Epoch 475/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.6287 - accuracy: 0.1086 - val_loss: 1.7970 - val_accuracy: 0.0205\n",
      "Epoch 476/600\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.6286 - accuracy: 0.1082 - val_loss: 1.8001 - val_accuracy: 0.0195\n",
      "Epoch 477/600\n",
      "32/32 [==============================] - 10s 326ms/step - loss: 0.6418 - accuracy: 0.1047 - val_loss: 1.7902 - val_accuracy: 0.0205\n",
      "Epoch 478/600\n",
      "32/32 [==============================] - 10s 326ms/step - loss: 0.6306 - accuracy: 0.1066 - val_loss: 1.7893 - val_accuracy: 0.0192\n",
      "Epoch 479/600\n",
      "32/32 [==============================] - 10s 327ms/step - loss: 0.6246 - accuracy: 0.1084 - val_loss: 1.7724 - val_accuracy: 0.0205\n",
      "Epoch 480/600\n",
      "32/32 [==============================] - 10s 323ms/step - loss: 0.6249 - accuracy: 0.1086 - val_loss: 1.8031 - val_accuracy: 0.0213\n",
      "Epoch 481/600\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.6237 - accuracy: 0.1094 - val_loss: 1.7907 - val_accuracy: 0.0198\n",
      "Epoch 482/600\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.6220 - accuracy: 0.1089 - val_loss: 1.7898 - val_accuracy: 0.0198\n",
      "Epoch 483/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.6303 - accuracy: 0.1076 - val_loss: 1.7655 - val_accuracy: 0.0198\n",
      "Epoch 484/600\n",
      "32/32 [==============================] - 10s 326ms/step - loss: 0.6199 - accuracy: 0.1097 - val_loss: 1.7824 - val_accuracy: 0.0198\n",
      "Epoch 485/600\n",
      "32/32 [==============================] - 10s 326ms/step - loss: 0.6146 - accuracy: 0.1113 - val_loss: 1.7958 - val_accuracy: 0.0207\n",
      "Epoch 486/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.6200 - accuracy: 0.1092 - val_loss: 1.7836 - val_accuracy: 0.0200\n",
      "Epoch 487/600\n",
      "32/32 [==============================] - 10s 327ms/step - loss: 0.6155 - accuracy: 0.1106 - val_loss: 1.7919 - val_accuracy: 0.0203\n",
      "Epoch 488/600\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.6151 - accuracy: 0.1111 - val_loss: 1.7828 - val_accuracy: 0.0198\n",
      "Epoch 489/600\n",
      "32/32 [==============================] - 10s 328ms/step - loss: 0.6126 - accuracy: 0.1109 - val_loss: 1.7861 - val_accuracy: 0.0200\n",
      "Epoch 490/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.6173 - accuracy: 0.1104 - val_loss: 1.7810 - val_accuracy: 0.0200\n",
      "Epoch 491/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.6091 - accuracy: 0.1115 - val_loss: 1.7929 - val_accuracy: 0.0203\n",
      "Epoch 492/600\n",
      "32/32 [==============================] - 10s 326ms/step - loss: 0.6088 - accuracy: 0.1123 - val_loss: 1.8062 - val_accuracy: 0.0198\n",
      "Epoch 493/600\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.6140 - accuracy: 0.1107 - val_loss: 1.7888 - val_accuracy: 0.0203\n",
      "Epoch 494/600\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.6105 - accuracy: 0.1116 - val_loss: 1.7797 - val_accuracy: 0.0195\n",
      "Epoch 495/600\n",
      "32/32 [==============================] - 10s 323ms/step - loss: 0.6115 - accuracy: 0.1119 - val_loss: 1.7773 - val_accuracy: 0.0195\n",
      "Epoch 496/600\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.6077 - accuracy: 0.1128 - val_loss: 1.7945 - val_accuracy: 0.0213\n",
      "Epoch 497/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.6037 - accuracy: 0.1116 - val_loss: 1.7887 - val_accuracy: 0.0205\n",
      "Epoch 498/600\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.6092 - accuracy: 0.1109 - val_loss: 1.7901 - val_accuracy: 0.0195\n",
      "Epoch 499/600\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.6084 - accuracy: 0.1121 - val_loss: 1.8021 - val_accuracy: 0.0205\n",
      "Epoch 500/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.5957 - accuracy: 0.1146 - val_loss: 1.7944 - val_accuracy: 0.0207\n",
      "Epoch 501/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.6005 - accuracy: 0.1136 - val_loss: 1.7864 - val_accuracy: 0.0200\n",
      "Epoch 502/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5973 - accuracy: 0.1136 - val_loss: 1.7934 - val_accuracy: 0.0190\n",
      "Epoch 503/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.5985 - accuracy: 0.1144 - val_loss: 1.7890 - val_accuracy: 0.0198\n",
      "Epoch 504/600\n",
      "32/32 [==============================] - 10s 323ms/step - loss: 0.6032 - accuracy: 0.1133 - val_loss: 1.7947 - val_accuracy: 0.0207\n",
      "Epoch 505/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5963 - accuracy: 0.1147 - val_loss: 1.7942 - val_accuracy: 0.0185\n",
      "Epoch 506/600\n",
      "32/32 [==============================] - 10s 326ms/step - loss: 0.5975 - accuracy: 0.1139 - val_loss: 1.7812 - val_accuracy: 0.0198\n",
      "Epoch 507/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.6248 - accuracy: 0.1102 - val_loss: 1.8006 - val_accuracy: 0.0203\n",
      "Epoch 508/600\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.5926 - accuracy: 0.1154 - val_loss: 1.7963 - val_accuracy: 0.0207\n",
      "Epoch 509/600\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.5908 - accuracy: 0.1159 - val_loss: 1.8014 - val_accuracy: 0.0200\n",
      "Epoch 510/600\n",
      "32/32 [==============================] - 10s 326ms/step - loss: 0.5873 - accuracy: 0.1160 - val_loss: 1.7946 - val_accuracy: 0.0200\n",
      "Epoch 511/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5884 - accuracy: 0.1168 - val_loss: 1.8071 - val_accuracy: 0.0203\n",
      "Epoch 512/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.6173 - accuracy: 0.1115 - val_loss: 1.8090 - val_accuracy: 0.0207\n",
      "Epoch 513/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5891 - accuracy: 0.1166 - val_loss: 1.7896 - val_accuracy: 0.0198\n",
      "Epoch 514/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.6143 - accuracy: 0.1119 - val_loss: 1.8002 - val_accuracy: 0.0200\n",
      "Epoch 515/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.6056 - accuracy: 0.1144 - val_loss: 1.7968 - val_accuracy: 0.0190\n",
      "Epoch 516/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.5868 - accuracy: 0.1168 - val_loss: 1.8015 - val_accuracy: 0.0200\n",
      "Epoch 517/600\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.5804 - accuracy: 0.1178 - val_loss: 1.8035 - val_accuracy: 0.0203\n",
      "Epoch 518/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5860 - accuracy: 0.1161 - val_loss: 1.7931 - val_accuracy: 0.0190\n",
      "Epoch 519/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5786 - accuracy: 0.1178 - val_loss: 1.8046 - val_accuracy: 0.0203\n",
      "Epoch 520/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5820 - accuracy: 0.1178 - val_loss: 1.8071 - val_accuracy: 0.0198\n",
      "Epoch 521/600\n",
      "32/32 [==============================] - 10s 326ms/step - loss: 0.5802 - accuracy: 0.1171 - val_loss: 1.7931 - val_accuracy: 0.0200\n",
      "Epoch 522/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.5832 - accuracy: 0.1184 - val_loss: 1.8036 - val_accuracy: 0.0185\n",
      "Epoch 523/600\n",
      "32/32 [==============================] - 10s 320ms/step - loss: 0.5810 - accuracy: 0.1166 - val_loss: 1.7949 - val_accuracy: 0.0205\n",
      "Epoch 524/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.5936 - accuracy: 0.1160 - val_loss: 1.7914 - val_accuracy: 0.0192\n",
      "Epoch 525/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.6111 - accuracy: 0.1133 - val_loss: 1.8090 - val_accuracy: 0.0205\n",
      "Epoch 526/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5873 - accuracy: 0.1181 - val_loss: 1.8093 - val_accuracy: 0.0203\n",
      "Epoch 527/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5863 - accuracy: 0.1177 - val_loss: 1.8112 - val_accuracy: 0.0190\n",
      "Epoch 528/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5737 - accuracy: 0.1196 - val_loss: 1.8044 - val_accuracy: 0.0205\n",
      "Epoch 529/600\n",
      "32/32 [==============================] - 10s 320ms/step - loss: 0.5835 - accuracy: 0.1183 - val_loss: 1.8124 - val_accuracy: 0.0190\n",
      "Epoch 530/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5757 - accuracy: 0.1194 - val_loss: 1.8076 - val_accuracy: 0.0192\n",
      "Epoch 531/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5733 - accuracy: 0.1206 - val_loss: 1.8082 - val_accuracy: 0.0190\n",
      "Epoch 532/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5671 - accuracy: 0.1221 - val_loss: 1.8030 - val_accuracy: 0.0192\n",
      "Epoch 533/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5673 - accuracy: 0.1210 - val_loss: 1.7920 - val_accuracy: 0.0188\n",
      "Epoch 534/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5736 - accuracy: 0.1201 - val_loss: 1.7989 - val_accuracy: 0.0200\n",
      "Epoch 535/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5725 - accuracy: 0.1199 - val_loss: 1.7980 - val_accuracy: 0.0190\n",
      "Epoch 536/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.5711 - accuracy: 0.1192 - val_loss: 1.7951 - val_accuracy: 0.0192\n",
      "Epoch 537/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5690 - accuracy: 0.1201 - val_loss: 1.8195 - val_accuracy: 0.0198\n",
      "Epoch 538/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5744 - accuracy: 0.1199 - val_loss: 1.7975 - val_accuracy: 0.0198\n",
      "Epoch 539/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5747 - accuracy: 0.1191 - val_loss: 1.8027 - val_accuracy: 0.0198\n",
      "Epoch 540/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5571 - accuracy: 0.1228 - val_loss: 1.8065 - val_accuracy: 0.0200\n",
      "Epoch 541/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5539 - accuracy: 0.1237 - val_loss: 1.8020 - val_accuracy: 0.0192\n",
      "Epoch 542/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5661 - accuracy: 0.1218 - val_loss: 1.8023 - val_accuracy: 0.0195\n",
      "Epoch 543/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5673 - accuracy: 0.1214 - val_loss: 1.8091 - val_accuracy: 0.0198\n",
      "Epoch 544/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5640 - accuracy: 0.1224 - val_loss: 1.7961 - val_accuracy: 0.0203\n",
      "Epoch 545/600\n",
      "32/32 [==============================] - 10s 320ms/step - loss: 0.5646 - accuracy: 0.1223 - val_loss: 1.8059 - val_accuracy: 0.0195\n",
      "Epoch 546/600\n",
      "32/32 [==============================] - 10s 320ms/step - loss: 0.5669 - accuracy: 0.1208 - val_loss: 1.7970 - val_accuracy: 0.0192\n",
      "Epoch 547/600\n",
      "32/32 [==============================] - 10s 323ms/step - loss: 0.5703 - accuracy: 0.1202 - val_loss: 1.7977 - val_accuracy: 0.0195\n",
      "Epoch 548/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.5587 - accuracy: 0.1237 - val_loss: 1.8079 - val_accuracy: 0.0207\n",
      "Epoch 549/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5523 - accuracy: 0.1244 - val_loss: 1.8104 - val_accuracy: 0.0210\n",
      "Epoch 550/600\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.5615 - accuracy: 0.1220 - val_loss: 1.7917 - val_accuracy: 0.0207\n",
      "Epoch 551/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5720 - accuracy: 0.1205 - val_loss: 1.8086 - val_accuracy: 0.0195\n",
      "Epoch 552/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5514 - accuracy: 0.1239 - val_loss: 1.8070 - val_accuracy: 0.0203\n",
      "Epoch 553/600\n",
      "32/32 [==============================] - 10s 323ms/step - loss: 0.5681 - accuracy: 0.1204 - val_loss: 1.8005 - val_accuracy: 0.0198\n",
      "Epoch 554/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5511 - accuracy: 0.1236 - val_loss: 1.8053 - val_accuracy: 0.0203\n",
      "Epoch 555/600\n",
      "32/32 [==============================] - 10s 323ms/step - loss: 0.5539 - accuracy: 0.1228 - val_loss: 1.8049 - val_accuracy: 0.0203\n",
      "Epoch 556/600\n",
      "32/32 [==============================] - 10s 319ms/step - loss: 0.5580 - accuracy: 0.1230 - val_loss: 1.8143 - val_accuracy: 0.0198\n",
      "Epoch 557/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5489 - accuracy: 0.1248 - val_loss: 1.8022 - val_accuracy: 0.0190\n",
      "Epoch 558/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5590 - accuracy: 0.1226 - val_loss: 1.8044 - val_accuracy: 0.0203\n",
      "Epoch 559/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5528 - accuracy: 0.1228 - val_loss: 1.8060 - val_accuracy: 0.0188\n",
      "Epoch 560/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5451 - accuracy: 0.1248 - val_loss: 1.8108 - val_accuracy: 0.0198\n",
      "Epoch 561/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5502 - accuracy: 0.1243 - val_loss: 1.8035 - val_accuracy: 0.0178\n",
      "Epoch 562/600\n",
      "32/32 [==============================] - 10s 320ms/step - loss: 0.5455 - accuracy: 0.1255 - val_loss: 1.8054 - val_accuracy: 0.0205\n",
      "Epoch 563/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5387 - accuracy: 0.1271 - val_loss: 1.8187 - val_accuracy: 0.0190\n",
      "Epoch 564/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5408 - accuracy: 0.1259 - val_loss: 1.8082 - val_accuracy: 0.0203\n",
      "Epoch 565/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5444 - accuracy: 0.1248 - val_loss: 1.8069 - val_accuracy: 0.0198\n",
      "Epoch 566/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5426 - accuracy: 0.1249 - val_loss: 1.8081 - val_accuracy: 0.0210\n",
      "Epoch 567/600\n",
      "32/32 [==============================] - 10s 320ms/step - loss: 0.5461 - accuracy: 0.1253 - val_loss: 1.8084 - val_accuracy: 0.0205\n",
      "Epoch 568/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5420 - accuracy: 0.1262 - val_loss: 1.7996 - val_accuracy: 0.0198\n",
      "Epoch 569/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.5378 - accuracy: 0.1268 - val_loss: 1.8119 - val_accuracy: 0.0205\n",
      "Epoch 570/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5406 - accuracy: 0.1262 - val_loss: 1.7985 - val_accuracy: 0.0192\n",
      "Epoch 571/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5405 - accuracy: 0.1258 - val_loss: 1.8116 - val_accuracy: 0.0203\n",
      "Epoch 572/600\n",
      "32/32 [==============================] - 10s 323ms/step - loss: 0.5376 - accuracy: 0.1273 - val_loss: 1.8142 - val_accuracy: 0.0198\n",
      "Epoch 573/600\n",
      "32/32 [==============================] - 10s 320ms/step - loss: 0.5399 - accuracy: 0.1261 - val_loss: 1.8004 - val_accuracy: 0.0190\n",
      "Epoch 574/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5347 - accuracy: 0.1285 - val_loss: 1.8092 - val_accuracy: 0.0203\n",
      "Epoch 575/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5333 - accuracy: 0.1270 - val_loss: 1.8171 - val_accuracy: 0.0198\n",
      "Epoch 576/600\n",
      "32/32 [==============================] - 10s 320ms/step - loss: 0.5437 - accuracy: 0.1256 - val_loss: 1.8061 - val_accuracy: 0.0198\n",
      "Epoch 577/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5367 - accuracy: 0.1272 - val_loss: 1.8010 - val_accuracy: 0.0192\n",
      "Epoch 578/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5325 - accuracy: 0.1274 - val_loss: 1.8123 - val_accuracy: 0.0198\n",
      "Epoch 579/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5552 - accuracy: 0.1238 - val_loss: 1.8023 - val_accuracy: 0.0207\n",
      "Epoch 580/600\n",
      "32/32 [==============================] - 10s 320ms/step - loss: 0.5475 - accuracy: 0.1250 - val_loss: 1.8091 - val_accuracy: 0.0203\n",
      "Epoch 581/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5341 - accuracy: 0.1272 - val_loss: 1.8154 - val_accuracy: 0.0210\n",
      "Epoch 582/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5329 - accuracy: 0.1274 - val_loss: 1.8052 - val_accuracy: 0.0205\n",
      "Epoch 583/600\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.5305 - accuracy: 0.1283 - val_loss: 1.8194 - val_accuracy: 0.0192\n",
      "Epoch 584/600\n",
      "32/32 [==============================] - 10s 326ms/step - loss: 0.5266 - accuracy: 0.1291 - val_loss: 1.8185 - val_accuracy: 0.0200\n",
      "Epoch 585/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5255 - accuracy: 0.1283 - val_loss: 1.8393 - val_accuracy: 0.0195\n",
      "Epoch 586/600\n",
      "32/32 [==============================] - 10s 323ms/step - loss: 0.5351 - accuracy: 0.1269 - val_loss: 1.8303 - val_accuracy: 0.0190\n",
      "Epoch 587/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5294 - accuracy: 0.1283 - val_loss: 1.8056 - val_accuracy: 0.0205\n",
      "Epoch 588/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5238 - accuracy: 0.1293 - val_loss: 1.8148 - val_accuracy: 0.0203\n",
      "Epoch 589/600\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.5283 - accuracy: 0.1281 - val_loss: 1.8159 - val_accuracy: 0.0192\n",
      "Epoch 590/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5492 - accuracy: 0.1249 - val_loss: 1.8274 - val_accuracy: 0.0210\n",
      "Epoch 591/600\n",
      "32/32 [==============================] - 10s 320ms/step - loss: 0.5344 - accuracy: 0.1273 - val_loss: 1.8247 - val_accuracy: 0.0192\n",
      "Epoch 592/600\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 0.5378 - accuracy: 0.1271 - val_loss: 1.8134 - val_accuracy: 0.0200\n",
      "Epoch 593/600\n",
      "32/32 [==============================] - 11s 340ms/step - loss: 0.5188 - accuracy: 0.1295 - val_loss: 1.8223 - val_accuracy: 0.0200\n",
      "Epoch 594/600\n",
      "32/32 [==============================] - 11s 348ms/step - loss: 0.5235 - accuracy: 0.1285 - val_loss: 1.8260 - val_accuracy: 0.0198\n",
      "Epoch 595/600\n",
      "32/32 [==============================] - 10s 327ms/step - loss: 0.5311 - accuracy: 0.1273 - val_loss: 1.8273 - val_accuracy: 0.0205\n",
      "Epoch 596/600\n",
      "32/32 [==============================] - 11s 345ms/step - loss: 0.5237 - accuracy: 0.1294 - val_loss: 1.8238 - val_accuracy: 0.0188\n",
      "Epoch 597/600\n",
      "32/32 [==============================] - 11s 360ms/step - loss: 0.5216 - accuracy: 0.1296 - val_loss: 1.8016 - val_accuracy: 0.0205\n",
      "Epoch 598/600\n",
      "32/32 [==============================] - 11s 340ms/step - loss: 0.5222 - accuracy: 0.1301 - val_loss: 1.8239 - val_accuracy: 0.0210\n",
      "Epoch 599/600\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.5124 - accuracy: 0.1309 - val_loss: 1.8177 - val_accuracy: 0.0192\n",
      "Epoch 600/600\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.5119 - accuracy: 0.1309 - val_loss: 1.8348 - val_accuracy: 0.0205\n"
     ]
    }
   ],
   "source": [
    "#Model\n",
    "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "#Compiling\n",
    "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
    "#Training\n",
    "training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n",
    "training_model.save('training_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration de test\n",
    "Maintenant, pour gérer une entrée que le modèle n'a pas vue, nous aurons besoin d'un modèle qui décode étape par étape au lieu d'utiliser le forçage de l'enseignant car le modèle que nous avons créé ne fonctionne que lorsque la séquence cible est connue . Dans l'application de chatbot génératif, nous ne saurons pas quelle sera la réponse générée pour l'entrée que l'utilisateur transmet. Pour ce faire, nous devrons construire un modèle seq2seq en morceaux individuels. Construisons d'abord un modèle d'encodeur avec des entrées d'encodeur et des états de sortie d'encodeur. Nous le ferons à l'aide du modèle préalablement formé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ST5NJzSwJlDB"
   },
   "outputs": [],
   "source": [
    "training_model = load_model('training_model.h5')\n",
    "\n",
    "encoder_inputs = training_model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous devrons créer des espaces réservés pour les états d'entrée du décodeur car nous ne savons pas ce que nous devons décoder ou quel état caché nous obtiendrons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
    "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
    "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant créer de nouveaux états et sorties de décodeur à l'aide du décodeur LSTM et de la couche dense que nous avons entraînés précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_states = [state_hidden, state_cell]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous avons la couche d'entrée du décodeur, les états finaux du codeur, les sorties du décodeur de la couche dense du décodeur et les états de sortie du décodeur qui sont la mémoire pendant le réseau d'un mot à l'autre. Nous pouvons rassembler tout cela maintenant et configurer le modèle de décodeur comme indiqué ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tester notre modèle\n",
    "- Enfin, nous allons créer une fonction qui accepte nos entrées de texte et génère une réponse à l'aide de l'encodeur et du décodeur que nous avons créés.\n",
    "- Dans la fonction ci-dessous, nous passons la matrice NumPy qui représente notre phrase de texte et nous en récupérons la réponse générée.\n",
    "- Voici ce qui se passe dans la fonction ci-dessous :\n",
    "  - 1.) Nous récupérons les états de sortie de l'encodeur \n",
    "  - 2.) Nous passons les états de sortie au décodeur (qui est notre état caché initial du décodeur) pour décoder la phrase mot         par mot \n",
    "  - 3.) Mettre à jour l'état caché du décodeur après le décodage de chaque mot afin que nous puissions utiliser les mots               précédemment décodés pour aider à décoder les nouveaux\n",
    "- Nous nous arrêterons une fois que nous rencontrerons le jeton '<END>' que nous avons ajouté aux séquences cibles dans notre tâche de prétraitement ou que nous atteignons la longueur maximale de la séquence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_response(test_input):\n",
    "    #Getting the output states to pass into the decoder\n",
    "    states_value = encoder_model.predict(test_input)\n",
    "    #Generating empty target sequence of length 1\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    #Setting the first token of target sequence with the start token\n",
    "    target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
    "    \n",
    "    #A variable to store our response word by word\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    stop_condition = False\n",
    "    while not stop_condition:\n",
    "          #Predicting output tokens with probabilities and states\n",
    "          output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n",
    "    #Choosing the one with highest probability\n",
    "          sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "          sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "          decoded_sentence += \" \" + sampled_token\n",
    "    #Stop if hit max length or found the stop token\n",
    "          if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "    #Update the target sequence\n",
    "          target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "          target_seq[0, 0, sampled_token_index] = 1.\n",
    "          #Update states\n",
    "          states_value = [hidden_state, cell_state]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "0JTKCjKVJ92i",
    "outputId": "f913afe7-5cc9-4fc5-f631-03ff762719be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\n",
      "hello\n",
      " i m happy to have to to to \n",
      "what is data science ?\n",
      " 8 \n",
      "how old are you ?\n",
      " is interesting but i think the ai the is editing not\n",
      "exit\n",
      "Ok, have a great day!\n"
     ]
    }
   ],
   "source": [
    "class ChatBot:\n",
    "  negative_responses = (\"no\", \"nope\", \"nah\", \"naw\", \"not a chance\", \"sorry\")\n",
    "  exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\")\n",
    "    \n",
    "#Method to start the conversation\n",
    "  def start_chat(self):\n",
    "    user_response = input(\"Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\\n\")\n",
    "    \n",
    "    if user_response in self.negative_responses:\n",
    "      print(\"Ok, have a great day!\")\n",
    "      return\n",
    "    self.chat(user_response)\n",
    "    \n",
    "#Method to handle the conversation\n",
    "  def chat(self, reply):\n",
    "    while not self.make_exit(reply):\n",
    "      reply = input(self.generate_response(reply)+\"\\n\")\n",
    "    \n",
    "  #Method to convert user input into a matrix\n",
    "  def string_to_matrix(self, user_input):\n",
    "    tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n",
    "    user_input_matrix = np.zeros(\n",
    "      (1, max_encoder_seq_length, num_encoder_tokens),\n",
    "      dtype='float32')\n",
    "    for timestep, token in enumerate(tokens):\n",
    "      if token in input_features_dict:\n",
    "        user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n",
    "    return user_input_matrix\n",
    "  \n",
    "  #Method that will create a response using seq2seq model we built\n",
    "  def generate_response(self, user_input):\n",
    "    input_matrix = self.string_to_matrix(user_input)\n",
    "    chatbot_response = decode_response(input_matrix)\n",
    "    #Remove <START> and <END> tokens from chatbot_response\n",
    "    chatbot_response = chatbot_response.replace(\"<START>\",'')\n",
    "    chatbot_response = chatbot_response.replace(\"<END>\",'')\n",
    "    return chatbot_response\n",
    "\n",
    "#Method to check for exit commands\n",
    "  def make_exit(self, reply):\n",
    "    for exit_command in self.exit_commands:\n",
    "      if exit_command in reply:\n",
    "        print(\"Ok, have a great day!\")\n",
    "        return True\n",
    "    return False\n",
    "  \n",
    "chatbot = ChatBot()\n",
    "chatbot.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "C7J5OMxJKEDK",
    "outputId": "008db9fd-b885-4bd6-ebb0-d86cd01d8825"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\n",
      "exit\n",
      "Ok, have a great day!\n"
     ]
    }
   ],
   "source": [
    "chatbot.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JN9jd7lQqtbq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "chatbot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
